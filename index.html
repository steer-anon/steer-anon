<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8" />
  <title>STEER</title>

  <link href="https://fonts.googleapis.com" rel="preconnect" />
  <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin="anonymous" />
  <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script>
  <script type="text/javascript">
    WebFont.load({
      google: {
        families: [
          "Lato:100,100italic,300,300italic,400,400italic,700,700italic,900,900italic",
        ],
      },
    });
  </script>

  <script type="module" src="https://md-block.verou.me/md-block.js"></script>



  <!-- Syntax highlighting -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.10.0/styles/rainbow.min.css"/>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.2.0/highlight.min.js"></script>
  <script>
    document.addEventListener("DOMContentLoaded", (event) => {
      document.querySelectorAll("pre code").forEach((block) => {
        hljs.highlightBlock(block);
      });
    });
  </script>

  <script src="https://code.jquery.com/jquery-3.7.0.slim.min.js"
    integrity="sha256-tG5mcZUtJsZvyKAxYLVXrmjKBVLd6VpVccqz/r4ypFE=" crossorigin="anonymous"></script>

  <!-- Bokeh -->
  <script type="text/javascript" src="https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js"></script>
  <script type="text/javascript">
    Bokeh.set_log_level("info");
  </script>
  <script type="application/json" id="1806">
    {"d60eec18-f31d-4133-8244-e88cb3bb701f":{"defs":[],"roots":{"references":[{"attributes":{"below":[{"id":"1636"}],"center":[{"id":"1639"},{"id":"1643"}],"height":200,"left":[{"id":"1640"}],"min_border":0,"renderers":[{"id":"1664"}],"title":{"id":"1666"},"toolbar":{"id":"1650"},"width":500,"x_range":{"id":"1628"},"x_scale":{"id":"1632"},"y_range":{"id":"1630"},"y_scale":{"id":"1634"}},"id":"1627","subtype":"Figure","type":"Plot"},{"attributes":{},"id":"1674","type":"Selection"},{"attributes":{},"id":"1648","type":"SaveTool"},{"attributes":{},"id":"1645","type":"PanTool"},{"attributes":{"data":{"bottom":{"__ndarray__":"ZmZmZmbmUUDNzMzMzMxHQM3MzMzMzE1AZmZmZmbmUUBmZmZmZqZTQM3MzMzMzE9AZmZmZmamU0DNzMzMzMxNQGZmZmZmJlRAZmZmZmYmUEBmZmZmZiZUQM3MzMzMzE1AZmZmZmamU0DNzMzMzMxPQGZmZmZmplNAzczMzMzMTUBmZmZmZiZTQM3MzMzMzE5AZmZmZmYmU0DNzMzMzExNQM3MzMzMzE1AZmZmZmbmUkDNzMzMzExMQGZmZmZm5lJAZmZmZmZmUkDNzMzMzExKQGZmZmZm5lJAZmZmZmZmUkBmZmZmZuZSQGZmZmZmZlJAzczMzMxMS0BmZmZmZuZSQGZmZmZm5lFAzczMzMzMR0A=","dtype":"float64","order":"little","shape":[34]},"duration":{"__ndarray__":"YFVVVVVV0D+wqqqqqqrjP8CqqqqqqsQ/wKqqqqqqyD9AVVVVVVXVPwAAAAAAAOM/QFVVVVVV1D9gVVVVVdXiP8Cqqqqqqtc/AAAAAAAA5j+AVVVVVVXPP6CqqqqqquM/wKqqqqqq1T8AAAAAAADjPwAAAAAAAM4/gKqqqqqqyD/AqqqqqqrXP6CqqqqqquI/wKqqqqqq0j8AAAAAAADiP0BVVVVVVeQ/AAAAAAAA1D8AAAAAAIDjP4BVVVVVVdE/gKqqqqqqxD9AVVVVVVXhPwAAAAAAALA/AKqqqqqqqj8AVlVVVVWxPwAAAAAAAN4/YFVVVVVV6D8AAAAAAADTPwAAAAAAANk/AAAAAAAA0z8=","dtype":"float64","order":"little","shape":[34]},"end_time":{"__ndarray__":"YFVVVVVV0D+wqqqqqqrkP7CqqqqqKuY/YFVVVVVV5z9QVVVVVRX2P7Cqqqqqqvo/UFVVVVUV/j8AAAAAAGABQAAAAAAAoANAqKqqqqoqBkBYVVVVVdUGQAAAAAAA4AlAAAAAAADAC0AAAAAAAOANQFhVVVVVNQ9AqKqqqqrqDkAAAAAAACASQFRVVVVVBRNArKqqqqrqE0CsqqqqqgoVQFRVVVVVZRdAAAAAAAAgFkAAAAAAAGAZQKyqqqqqChhAVFVVVVW1GUBUVVVVVUUbQKyqqqqqehpAVFVVVVXVGkCsqqqqqhobQKyqqqqqCh1AAAAAAABQHkAAAAAAAAAeQKyqqqqqah9AVFVVVVUlH0A=","dtype":"float64","order":"little","shape":[34]},"fill_alpha":{"__ndarray__":"AAAAAACA1D8AAAAAAADQPwAAAAAAANM/AAAAAACA2D8AAAAAAADWPwAAAAAAAMs/AAAAAAAA1z8AAAAAAADNPwAAAAAAgNk/AAAAAAAA1T8AAAAAAIDUPwAAAAAAAME/AAAAAAAA0z8AAAAAAADKPwAAAAAAgNU/AAAAAAAAzT8AAAAAAADYPwAAAAAAgNQ/AAAAAACA1T8AAAAAAADVPwAAAAAAANE/AAAAAAAA2D8AAAAAAADXPwAAAAAAgNU/AAAAAAAA1j8AAAAAAIDUPwAAAAAAgNY/AAAAAAAA1D8AAAAAAIDXPwAAAAAAgN4/AAAAAAAA0z8AAAAAAADWPwAAAAAAgNI/AAAAAAAA0j8=","dtype":"float64","order":"little","shape":[34]},"index":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33],"instrument":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"pitch":[72,48,60,72,79,64,79,60,81,65,81,60,79,64,79,60,77,62,77,59,60,76,57,76,74,53,76,74,76,74,55,76,72,48],"program":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],"start_time":{"__ndarray__":"AAAAAAAAAAAAAAAAAACgPwAAAAAAAOE/sKqqqqoq4T8AAAAAAMDwP7CqqqqqKvE/AAAAAAAA+T9QVVVVVVX5P6iqqqqqqgBAqKqqqqqqAEAAAAAAAOAEQFhVVVVV9QRAqKqqqqoKCUAAAAAAACAJQFhVVVVVVQ1AAAAAAABgDUBUVVVVVaUQQAAAAAAAsBBAAAAAAADAEkCsqqqqqsoSQKyqqqqq2hRAAAAAAADgFEAAAAAAAPAWQFRVVVVV9RZAAAAAAAAQGUCsqqqqqhoZQKyqqqqqOhpAAAAAAACgGkBUVVVVVdUaQKyqqqqqKhtAVFVVVVVFG0AAAAAAANAcQKyqqqqq2h1AVFVVVVX1HUA=","dtype":"float64","order":"little","shape":[34]},"top":{"__ndarray__":"mpmZmZkZUkAzMzMzMzNIQDMzMzMzM05AmpmZmZkZUkCamZmZmdlTQJqZmZmZGVBAmpmZmZnZU0AzMzMzMzNOQJqZmZmZWVRAmpmZmZlZUECamZmZmVlUQDMzMzMzM05AmpmZmZnZU0CamZmZmRlQQJqZmZmZ2VNAMzMzMzMzTkCamZmZmVlTQDMzMzMzM09AmpmZmZlZU0AzMzMzM7NNQDMzMzMzM05AmpmZmZkZU0AzMzMzM7NMQJqZmZmZGVNAmpmZmZmZUkAzMzMzM7NKQJqZmZmZGVNAmpmZmZmZUkCamZmZmRlTQJqZmZmZmVJAMzMzMzOzS0CamZmZmRlTQJqZmZmZGVJAMzMzMzMzSEA=","dtype":"float64","order":"little","shape":[34]},"velocity":[41,32,38,49,44,27,46,29,51,42,41,17,38,26,43,29,48,41,43,42,34,48,46,43,44,41,45,40,47,61,38,44,37,36]},"selected":{"id":"1674"},"selection_policy":{"id":"1673"}},"id":"1659","type":"ColumnDataSource"},{"attributes":{},"id":"1634","type":"LinearScale"},{"attributes":{"axis_label":"time (sec)","coordinates":null,"formatter":{"id":"1671"},"group":null,"major_label_policy":{"id":"1672"},"ticker":{"id":"1637"}},"id":"1636","type":"LinearAxis"},{"attributes":{},"id":"1637","type":"BasicTicker"},{"attributes":{},"id":"1647","type":"ResetTool"},{"attributes":{},"id":"1628","type":"DataRange1d"},{"attributes":{"coordinates":null,"data_source":{"id":"1659"},"glyph":{"id":"1661"},"group":null,"hover_glyph":null,"muted_glyph":{"id":"1663"},"nonselection_glyph":{"id":"1662"},"view":{"id":"1665"}},"id":"1664","type":"GlyphRenderer"},{"attributes":{"axis":{"id":"1640"},"coordinates":null,"dimension":1,"group":null,"ticker":{"id":"1658"}},"id":"1643","type":"Grid"},{"attributes":{"bottom":{"field":"bottom"},"fill_alpha":{"value":0.2},"fill_color":{"value":"#d53e4f"},"hatch_alpha":{"value":0.2},"left":{"field":"start_time"},"line_alpha":{"value":0.2},"right":{"field":"end_time"},"top":{"field":"top"}},"id":"1663","type":"Quad"},{"attributes":{"bottom":{"field":"bottom"},"fill_alpha":{"value":0.1},"fill_color":{"value":"#d53e4f"},"hatch_alpha":{"value":0.1},"left":{"field":"start_time"},"line_alpha":{"value":0.1},"right":{"field":"end_time"},"top":{"field":"top"}},"id":"1662","type":"Quad"},{"attributes":{"interval":12},"id":"1658","type":"SingleIntervalTicker"},{"attributes":{"coordinates":null,"group":null},"id":"1666","type":"Title"},{"attributes":{},"id":"1672","type":"AllLabels"},{"attributes":{"source":{"id":"1659"}},"id":"1665","type":"CDSView"},{"attributes":{"interval":12},"id":"1656","type":"SingleIntervalTicker"},{"attributes":{"axis":{"id":"1636"},"coordinates":null,"group":null,"ticker":null},"id":"1639","type":"Grid"},{"attributes":{"tools":[{"id":"1644"},{"id":"1645"},{"id":"1646"},{"id":"1647"},{"id":"1648"}]},"id":"1650","type":"Toolbar"},{"attributes":{"overlay":{"id":"1649"}},"id":"1646","type":"BoxZoomTool"},{"attributes":{},"id":"1630","type":"DataRange1d"},{"attributes":{},"id":"1671","type":"BasicTickFormatter"},{"attributes":{"callback":null,"tooltips":[["pitch","@pitch"],["program","@program"],["velo","@velocity"],["duration","@duration"],["start_time","@start_time"],["end_time","@end_time"],["velocity","@velocity"],["fill_alpha","@fill_alpha"]]},"id":"1644","type":"HoverTool"},{"attributes":{},"id":"1669","type":"AllLabels"},{"attributes":{"bottom_units":"screen","coordinates":null,"fill_alpha":0.5,"fill_color":"lightgrey","group":null,"left_units":"screen","level":"overlay","line_alpha":1.0,"line_color":"black","line_dash":[4,4],"line_width":2,"right_units":"screen","syncable":false,"top_units":"screen"},"id":"1649","type":"BoxAnnotation"},{"attributes":{},"id":"1668","type":"BasicTickFormatter"},{"attributes":{},"id":"1673","type":"UnionRenderers"},{"attributes":{"bottom":{"field":"bottom"},"fill_alpha":{"field":"fill_alpha"},"fill_color":{"value":"#d53e4f"},"left":{"field":"start_time"},"right":{"field":"end_time"},"top":{"field":"top"}},"id":"1661","type":"Quad"},{"attributes":{"axis_label":"pitch (MIDI)","coordinates":null,"formatter":{"id":"1668"},"group":null,"major_label_policy":{"id":"1669"},"ticker":{"id":"1656"}},"id":"1640","type":"LinearAxis"},{"attributes":{},"id":"1632","type":"LinearScale"}],"root_ids":["1627"]},"title":"Bokeh Application","version":"2.4.3"}}
  </script>
  <script type="text/javascript">
    (function () {
      const fn = function () {
        Bokeh.safely(function () {
          (function (root) {
            function embed_document(root) {
              const docs_json = document.getElementById('1806').textContent;
              const render_items = [{ "docid": "d60eec18-f31d-4133-8244-e88cb3bb701f", "root_ids": ["1627"], "roots": { "1627": "53c9966a-3bb0-4499-ad07-58da8ce3ea32" } }];
              root.Bokeh.embed.embed_items(docs_json, render_items);
            }
            if (root.Bokeh !== undefined) {
              embed_document(root);
            } else {
              let attempts = 0;
              const timer = setInterval(function (root) {
                if (root.Bokeh !== undefined) {
                  clearInterval(timer);
                  embed_document(root);
                } else {
                  attempts++;
                  if (attempts > 100) {
                    clearInterval(timer);
                    console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");
                  }
                }
              }, 10, root)
            }
          })(window);
        });
      };
      if (document.readyState != "loading") fn();
      else document.addEventListener("DOMContentLoaded", fn);
    })();
  </script>

  <!-- Latex. -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" rel="stylesheet"
    type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@tabler/icons@latest/iconfont/tabler-icons.min.css" />
  <link href="style.css" rel="stylesheet" type="text/css" />
</head>

<body>
  <h1 style="font-family: Lato; margin: 0.25em 0">
    STEER: Bridging Vision-Language Models <br />
    and Low-Level Control for Adaptable Robotic Manipulation
  </h1>

  <div style="text-align: center; font-weight: 600">in submission, ICRA 2025</div>
  <div style="height: 1em"></div>

  <!-- Authors -->
  <div style="
      display: flex;
      flex-wrap: wrap;
      text-align: center;
      justify-content: center;
      gap: 0.4em 1.25em;
      max-width: 60em;
      margin: 0 auto;
      font-weight: 600;
      color: #666;
    ">
    <div>
      <a target="_blank">Laura Smith<sup>1,2</sup></a>
      <div style="width: 1.25em; display: inline-block"></div>
      <a target="_blank">Alex Irpan<sup>1</sup></a>
      <div style="width: 1.25em; display: inline-block"></div>
      <a target="_blank">Montserrat Gonzalez Arenas<sup>1</sup></a>
    </div>
    <div>
      <a target="_blank">Sean Kirmani<sup>1</sup></a>
      <div style="width: 1.25em; display: inline-block"></div>
      <a target="_blank">Dmitry Kalashnikov<sup>1</sup></a>
      <div style="width: 1.25em; display: inline-block"></div>
      <a target="_blank">Dhruv Shah<sup>1</sup></a>
      <div style="width: 1.25em; display: inline-block"></div>
      <a target="_blank">Ted Xiao<sup>1</sup></a>
      <div style="width: 1.25em; display: inline-block"></div>
    </div>
  </div>
  <div style="height: 1em"></div>

  <!-- Affiliations -->
  <div style="
      display: flex;
      justify-content: center;
      gap: 2em;
      max-width: 50em;
      margin: 0 auto;
      font-weight: 400;
    ">
    <div><sup>1</sup>Google DeepMind</div>
    <div><sup>2</sup>UC Berkeley</div>
  </div>
  <div style="height: 2em"></div>

  <!-- Links -->
  <div style="
      display: flex;
      justify-content: center;
      gap: 0.5em 1em;
      flex-wrap: wrap;
    ">
    <a href="" target="_blank">
      <!-- <button>
        <i class="ti ti-article"></i>
        Paper
      </button> -->
    </a>
    <script type="text/javascript">
      function toggleBibtex() {
        const $bibtex = $("#bibtex");
        $bibtex.css(
          "display",
          $bibtex.css("display") === "none" ? "block" : "none",
        );
      }
    </script>
    <a onclick="toggleBibtex()">
      <!-- <button>
        <i class="ti ti-book-2"></i>
        BibTeX
      </button> -->
    </a>
  </div>

  <section id="bibtex" style="display: none">
    <div style="height: 1em"></div>
    <div style="height: 1em"></div>
    <p>
      <code style="
          font-family:
            Courier New,
            Courier,
            monospace;
          white-space: nowrap;
          width: 100%;
          max-width: 100%;
          overflow: scroll;
          display: block;
          background-color: #f7f7f7;
          padding: 1em;
          box-sizing: border-box;
          border-radius: 0.5em;
        ">
        @inproceedings{TEMP,<br />
        &nbsp;&nbsp;&nbsp;&nbsp;author = {},<br />
        &nbsp;&nbsp;&nbsp;&nbsp;title = {TEMP},<br />
        &nbsp;&nbsp;&nbsp;&nbsp;booktitle = {TEMP},<br />
        &nbsp;&nbsp;&nbsp;&nbsp;year = {2025},<br />
        }
      </code>
    </p>
  </section>
  <div style="height: 1em"></div>

  <!-- tldr -->
  <div style="max-width: 600px; margin: 0 auto; text-align: center;">
    <strong>TLDR</strong>
    <em>
      We propose a system which leverages dense language annotations of offline data to learn low-level manipulation skills that can be modulated or repurposed in semantically meaningful ways to adapt to new situations.
    </em>
  </div>
  <div style="height: 1em"></div>

  <section>
    <h2>Overview</h2>

    <div style="display: flex; justify-content: center;">
      <video controls src="assets/videos/steer_half_compressed.mp4" style="width: 80%; max-width: 800px;" autoplay loop muted></video>
    </div>
    
    <!-- <figcaption style="font-size: 0.8em; text-align: center; margin-top: 1em;"> Recent advances have showcased the opportunity of leveraging the broad semantic understanding learned by vision-language models (VLMs) in robot learning; however, connecting VLMs effectively to robot control remains an open question since physical robot data is relatively sparse and narrow compared to internet-scale VLM training data. We propose STEER, a system for bridging this gap by learning flexible, low- level manipulation skills that can be modulated or repurposed to adapt to new situations. We show that training low-level learned policies on structured, dense re-annotation of existing robot datasets exposes an intuitive and flexible interface for humans or VLMs to guide them in unfamiliar scenarios or to perform new tasks using common-sense reasoning. We demonstrate the skills learned via STEER can be combined to synthesize novel behaviors to achieve held-out tasks without additional training.</figcaption> -->
    <div style="height: 2em"></div>
    <p>
    Recent advances have showcased the opportunity of leveraging the broad semantic understanding learned by vision-language models (VLMs) in robot learning; however, connecting VLMs effectively to robot control remains an open question since physical robot data is relatively sparse and narrow compared to internet-scale VLM training data. We propose STEER, a system for bridging this gap by learning flexible, low- level manipulation skills that can be modulated or repurposed to adapt to new situations. We show that training low-level learned policies on structured, dense re-annotation of existing robot datasets exposes an intuitive and flexible interface for humans or VLMs to guide them in unfamiliar scenarios or to perform new tasks using common-sense reasoning. We demonstrate the skills learned via STEER can be combined to synthesize novel behaviors to achieve held-out tasks without additional training.
    </p>
  </section>

  <section>
    <h2>Qualitative Comparisons using Human Instructions</h2>

    <!-- Carousel Wrapper -->
    <div class="carousel-container" id="carousel1">
      <!-- Heading to put the task name with some nice margins-->
      <h3 style="margin: 1em 0">Pouring</h3>

      <!-- Left arrow to navigate to the previous set -->
      <button class="carousel-button left" onclick="prevSlide('carousel1')">&#10094;</button>

      <!-- Carousel Track for the video slides -->
      <div class="carousel-track">
          <div class="carousel-slide">
              <figure class="video-container-small">
                  <video src="assets/videos/pouring/ours (human)/0.mp4" controls autoplay loop muted></video>
                  <figcaption>STEER (ours)</figcaption>
              </figure>
              <figure class="video-container-small">
                  <video src="assets/videos/pouring/OpenVLA/0.mp4" controls autoplay loop muted></video>
                  <figcaption>OpenVLA</figcaption>
              </figure>
              <figure class="video-container-small">
                  <video src="assets/videos/pouring/rt1/0.mp4" controls autoplay loop muted></video>
                  <figcaption>RT-1</figcaption>
              </figure>
              <figure class="video-container-small">
                <video src="assets/videos/pouring/RTH ablation/0.mp4" controls autoplay loop muted></video>
                <figcaption>RT-H language motions</figcaption>
              </figure>
              <figure class="video-container-small">
                <video src="assets/videos/pouring/goal images/paired/0.mp4" controls autoplay loop muted></video>
                <figcaption>Image GCBC</figcaption>
              </figure>
          </div>
          <div class="carousel-slide">
            <figure class="video-container-small">
                <video src="assets/videos/pouring/ours (human)/1.mp4" controls autoplay loop muted></video>
                <figcaption>STEER (ours)</figcaption>
            </figure>
            <figure class="video-container-small">
                <video src="assets/videos/pouring/OpenVLA/1.mp4" controls autoplay loop muted></video>
                <figcaption>OpenVLA</figcaption>
            </figure>
            <figure class="video-container-small">
                <video src="assets/videos/pouring/rt1/1.mp4" controls autoplay loop muted></video>
                <figcaption>RT-1</figcaption>
            </figure>
            <figure class="video-container-small">
              <video src="assets/videos/pouring/RTH ablation/1.mp4" controls autoplay loop muted></video>
              <figcaption>RT-H language motions</figcaption>
            </figure>
            <figure class="video-container-small">
              <video src="assets/videos/pouring/goal images/paired/1.mp4" controls autoplay loop muted></video>
              <figcaption>Image GCBC</figcaption>
            </figure>
          </div>
          <div class="carousel-slide">
            <figure class="video-container-small">
                <video src="assets/videos/pouring/ours (human)/2.mp4" controls autoplay loop muted></video>
                <figcaption>STEER (ours)</figcaption>
            </figure>
            <figure class="video-container-small">
                <video src="assets/videos/pouring/OpenVLA/2.mp4" controls autoplay loop muted></video>
                <figcaption>OpenVLA</figcaption>
            </figure>
            <figure class="video-container-small">
                <video src="assets/videos/pouring/rt1/2.mp4" controls autoplay loop muted></video>
                <figcaption>RT-1</figcaption>
            </figure>
            <figure class="video-container-small">
              <video src="assets/videos/pouring/RTH ablation/2.mp4" controls autoplay loop muted></video>
              <figcaption>RT-H language motions</figcaption>
            </figure>
            <figure class="video-container-small">
              <video src="assets/videos/pouring/goal images/paired/2.mp4" controls autoplay loop muted></video>
              <figcaption>Image GCBC</figcaption>
            </figure>
          </div>
          <div class="carousel-slide">
            <figure class="video-container-small">
                <video src="assets/videos/pouring/ours (human)/3.mp4" controls autoplay loop muted></video>
                <figcaption>STEER (ours)</figcaption>
            </figure>
            <figure class="video-container-small">
                <video src="assets/videos/pouring/OpenVLA/3.mp4" controls autoplay loop muted></video>
                <figcaption>OpenVLA</figcaption>
            </figure>
            <figure class="video-container-small">
                <video src="assets/videos/pouring/rt1/3.mp4" controls autoplay loop muted></video>
                <figcaption>RT-1</figcaption>
            </figure>
            <figure class="video-container-small">
              <video src="assets/videos/pouring/RTH ablation/3.mp4" controls autoplay loop muted></video>
              <figcaption>RT-H language motions</figcaption>
            </figure>
            <figure class="video-container-small">
              <video src="assets/videos/pouring/goal images/paired/3.mp4" controls autoplay loop muted></video>
              <figcaption>Image GCBC</figcaption>
            </figure>
          </div>
          <div class="carousel-slide">
            <figure class="video-container-small">
                <video src="assets/videos/pouring/ours (human)/4.mp4" controls autoplay loop muted></video>
                <figcaption>STEER (ours)</figcaption>
            </figure>
            <figure class="video-container-small">
                <video src="assets/videos/pouring/OpenVLA/4.mp4" controls autoplay loop muted></video>
                <figcaption>OpenVLA</figcaption>
            </figure>
            <figure class="video-container-small">
                <video src="assets/videos/pouring/rt1/4.mp4" controls autoplay loop muted></video>
                <figcaption>RT-1</figcaption>
            </figure>
            <figure class="video-container-small">
              <video src="assets/videos/pouring/RTH ablation/4.mp4" controls autoplay loop muted></video>
              <figcaption>RT-H language motions</figcaption>
            </figure>
            <figure class="video-container-small">
              <video src="assets/videos/pouring/goal images/paired/4.mp4" controls autoplay loop muted></video>
              <figcaption>Image GCBC</figcaption>
            </figure>
          </div>
      </div>
      <!-- Right arrow to navigate to the next set -->
      <button class="carousel-button right" onclick="nextSlide('carousel1')">&#10095;</button>
  </div>

    <!-- Carousel Wrapper -->
    <div class="carousel-container" id="carousel2">
      <!-- Heading to put the task name with some nice margins-->
      <h3 style="margin: 1em 0">Grasping Potted Plant</h3>

      <!-- Left arrow to navigate to the previous set -->
      <button class="carousel-button left" onclick="prevSlide('carousel2')">&#10094;</button>

      <!-- Carousel Track for the video slides -->
      <div class="carousel-track">
          <div class="carousel-slide">
              <figure class="video-container">
                  <video src="assets/videos/grasping/plant/ours/0_c.mp4" controls autoplay loop muted></video>
                  <figcaption>STEER (ours)</figcaption>
              </figure>
              <figure class="video-container">
                  <video src="assets/videos/grasping/plant/openVLA/0.mp4" controls autoplay loop muted></video>
                  <figcaption>OpenVLA</figcaption>
              </figure>
              <figure class="video-container">
                  <video src="assets/videos/grasping/plant/rt1/0_c.mp4" controls autoplay loop muted></video>
                  <figcaption>RT-1</figcaption>
              </figure>
          </div>
          <div class="carousel-slide">
            <figure class="video-container">
                <video src="assets/videos/grasping/plant/ours/1_c.mp4" controls autoplay loop muted></video>
                <figcaption>STEER (ours)</figcaption>
            </figure>
            <figure class="video-container">
                <video src="assets/videos/grasping/plant/openVLA/1.mp4" controls autoplay loop muted></video>
                <figcaption>OpenVLA</figcaption>
            </figure>
            <figure class="video-container">
                <video src="assets/videos/grasping/plant/rt1/1_c.mp4" controls autoplay loop muted></video>
                <figcaption>RT-1</figcaption>
            </figure>
          </div>
          <div class="carousel-slide">
            <figure class="video-container">
                <video src="assets/videos/grasping/plant/ours/2_c.mp4" controls autoplay loop muted></video>
                <figcaption>STEER (ours)</figcaption>
            </figure>
            <figure class="video-container">
                <video src="assets/videos/grasping/plant/openVLA/2.mp4" controls autoplay loop muted></video>
                <figcaption>OpenVLA</figcaption>
            </figure>
            <figure class="video-container">
                <video src="assets/videos/grasping/plant/rt1/2_c.mp4" controls autoplay loop muted></video>
                <figcaption>RT-1</figcaption>
            </figure>
          </div>
          <div class="carousel-slide">
            <figure class="video-container">
                <video src="assets/videos/grasping/plant/ours/3_c.mp4" controls autoplay loop muted></video>
                <figcaption>STEER (ours)</figcaption>
            </figure>
            <figure class="video-container">
                <video src="assets/videos/grasping/plant/openVLA/3.mp4" controls autoplay loop muted></video>
                <figcaption>OpenVLA</figcaption>
            </figure>
            <figure class="video-container">
                <video src="assets/videos/grasping/plant/rt1/3_c.mp4" controls autoplay loop muted></video>
                <figcaption>RT-1</figcaption>
            </figure>
          </div>
          <div class="carousel-slide">
            <figure class="video-container">
                <video src="assets/videos/grasping/plant/ours/4_c.mp4" controls autoplay loop muted></video>
                <figcaption>STEER (ours)</figcaption>
            </figure>
            <figure class="video-container">
                <video src="assets/videos/grasping/plant/openVLA/4.mp4" controls autoplay loop muted></video>
                <figcaption>OpenVLA</figcaption>
            </figure>
            <figure class="video-container">
                <video src="assets/videos/grasping/plant/rt1/4_c.mp4" controls autoplay loop muted></video>
                <figcaption>RT-1</figcaption>
            </figure>
          </div>
      </div>
      <button class="carousel-button right" onclick="nextSlide('carousel2')">&#10095;</button>
  </div>


    <!-- Carousel Wrapper -->
    <div class="carousel-container" id="carousel3">
      <!-- Heading to put the task name with some nice margins-->
      <h3 style="margin: 1em 0">Grasping Kettle</h3>

      <!-- Left arrow to navigate to the previous set -->
      <button class="carousel-button left" onclick="prevSlide('carousel3')">&#10094;</button>

      <!-- Carousel Track for the video slides -->
      <div class="carousel-track">
          <div class="carousel-slide">
              <figure class="video-container">
                  <img src="assets/videos/grasping/kettle/ours/0.gif"></img>
                  <figcaption>STEER (ours)</figcaption>
              </figure>
              <figure class="video-container">
                  <img src="assets/videos/grasping/kettle/OpenVLA/0.gif"></img>
                  <figcaption>OpenVLA</figcaption>
              </figure>
              <figure class="video-container">
                  <img src="assets/videos/grasping/kettle/rt1/0.gif"></img>
                  <figcaption>RT-1</figcaption>
              </figure>
          </div>
          <div class="carousel-slide">
            <figure class="video-container">
                <img src="assets/videos/grasping/kettle/ours/1.gif"></img>
                <figcaption>STEER (ours)</figcaption>
            </figure>
            <figure class="video-container">
                <img src="assets/videos/grasping/kettle/OpenVLA/1.gif"></img>
                <figcaption>OpenVLA</figcaption>
            </figure>
            <figure class="video-container">
                <img src="assets/videos/grasping/kettle/rt1/1.gif"></img>
                <figcaption>RT-1</figcaption>
            </figure>
          </div>
          <div class="carousel-slide">
            <figure class="video-container">
                <img src="assets/videos/grasping/kettle/ours/2.gif"></img>
                <figcaption>STEER (ours)</figcaption>
            </figure>
            <figure class="video-container">
                <img src="assets/videos/grasping/kettle/OpenVLA/2.gif"></img>
                <figcaption>OpenVLA</figcaption>
            </figure>
            <figure class="video-container">
                <img src="assets/videos/grasping/kettle/rt1/2.gif"></img>
                <figcaption>RT-1</figcaption>
            </figure>
          </div>
          <div class="carousel-slide">
            <figure class="video-container">
                <img src="assets/videos/grasping/kettle/ours/3.gif"></img>
                <figcaption>STEER (ours)</figcaption>
            </figure>
            <figure class="video-container">
                <img src="assets/videos/grasping/kettle/OpenVLA/3.gif"></img>
                <figcaption>OpenVLA</figcaption>
            </figure>
            <figure class="video-container">
                <img src="assets/videos/grasping/kettle/rt1/3.gif"></img>
                <figcaption>RT-1</figcaption>
            </figure>
          </div>
          <div class="carousel-slide">
            <figure class="video-container">
                <img src="assets/videos/grasping/kettle/ours/4.gif"></img>
                <figcaption>STEER (ours)</figcaption>
            </figure>
            <figure class="video-container">
                <img src="assets/videos/grasping/kettle/OpenVLA/4.gif"></img>
                <figcaption>OpenVLA</figcaption>
            </figure>
            <figure class="video-container">
                <img src="assets/videos/grasping/kettle/rt1/4.gif"></img>
                <figcaption>RT-1</figcaption>
            </figure>
          </div>
      </div>
      <button class="carousel-button right" onclick="nextSlide('carousel3')">&#10095;</button>
  </div>


    <!-- Carousel Wrapper -->
    <div class="carousel-container" id="carousel4">
      <!-- Heading to put the task name with some nice margins-->
      <h3 style="margin: 1em 0">Grasping in Clutter</h3>

      <!-- Left arrow to navigate to the previous set -->
      <button class="carousel-button left" onclick="prevSlide('carousel4')">&#10094;</button>

      <!-- Carousel Track for the video slides -->
      <div class="carousel-track">
          <div class="carousel-slide">
              <figure class="video-container">
                  <video src="assets/videos/grasping/fruits/ours/0.mp4" controls autoplay loop muted></video>
                  <figcaption>STEER (ours)</figcaption>
              </figure>
              <figure class="video-container">
                  <video src="assets/videos/grasping/fruits/OpenVLA/0.mp4" controls autoplay loop muted></video>
                  <figcaption>OpenVLA</figcaption>
              </figure>
              <figure class="video-container">
                  <video src="assets/videos/grasping/fruits/rt1/0.mp4" controls autoplay loop muted></video>
                  <figcaption>RT-1</figcaption>
              </figure>
          </div>
          <div class="carousel-slide">
            <figure class="video-container">
                <video src="assets/videos/grasping/fruits/ours/1.mp4" controls autoplay loop muted></video>
                <figcaption>STEER (ours)</figcaption>
            </figure>
            <figure class="video-container">
                <video src="assets/videos/grasping/fruits/OpenVLA/1.mp4" controls autoplay loop muted></video>
                <figcaption>OpenVLA</figcaption>
            </figure>
            <figure class="video-container">
                <video src="assets/videos/grasping/fruits/rt1/1.mp4" controls autoplay loop muted></video>
                <figcaption>RT-1</figcaption>
            </figure>
          </div>
          <div class="carousel-slide">
            <figure class="video-container">
                <video src="assets/videos/grasping/fruits/ours/2.mp4" controls autoplay loop muted></video>
                <figcaption>STEER (ours)</figcaption>
            </figure>
            <figure class="video-container">
                <video src="assets/videos/grasping/fruits/OpenVLA/2.mp4" controls autoplay loop muted></video>
                <figcaption>OpenVLA</figcaption>
            </figure>
            <figure class="video-container">
                <video src="assets/videos/grasping/fruits/rt1/2.mp4" controls autoplay loop muted></video>
                <figcaption>RT-1</figcaption>
            </figure>
          </div>
          <div class="carousel-slide">
            <figure class="video-container">
                <video src="assets/videos/grasping/fruits/ours/3.mp4" controls autoplay loop muted></video>
                <figcaption>STEER (ours)</figcaption>
            </figure>
            <figure class="video-container">
                <video src="assets/videos/grasping/fruits/OpenVLA/3.mp4" controls autoplay loop muted></video>
                <figcaption>OpenVLA</figcaption>
            </figure>
            <figure class="video-container">
                <video src="assets/videos/grasping/fruits/rt1/3.mp4" controls autoplay loop muted></video>
                <figcaption>RT-1</figcaption>
            </figure>
          </div>
          <div class="carousel-slide">
            <figure class="video-container">
                <video src="assets/videos/grasping/fruits/ours/4.mp4" controls autoplay loop muted></video>
                <figcaption>STEER (ours)</figcaption>
            </figure>
            <figure class="video-container">
                <video src="assets/videos/grasping/fruits/OpenVLA/4.mp4" controls autoplay loop muted></video>
                <figcaption>OpenVLA</figcaption>
            </figure>
            <figure class="video-container">
                <video src="assets/videos/grasping/fruits/rt1/4.mp4" controls autoplay loop muted></video>
                <figcaption>RT-1</figcaption>
            </figure>
          </div>
      </div>
      <button class="carousel-button right" onclick="nextSlide('carousel4')">&#10095;</button>
  </div>
  </section>

<h2>VLM STEERing</h2>


<section class="vlm-section">
  <p>
    We show that we can automate STEER with an off-the-shelf VLM (in this case we use Gemini 1.5 Pro). In our experiments, we use the same system prompt as provided below. In the results section, we show the VLM outputs which are automatically parsed for code that is subsequently executed on the real robot.
  </p>

  <h3 style="margin: 1em 0">System Prompt</h3>
    <p id="system-prompt">
      <!-- <div style="background-color: #e8f8e8; padding: .5em; border-radius: 0.5em; margin-bottom: 1em; border: 1px solid #b3d9b3; margin-top: 1em;"> -->
        You are a helpful robot with one right arm. You are equipped with a large parallel jaw gripper end-effector.
        You will be asked to perform different tasks that involve interacting with the objects in the workspace.
        You are provided with an API to execute actions in the physical world to complete the task. These are the <strong>only</strong> actions you can perform.
        The procedure to perform a task is as follows:
            <ol style="margin-left: 1em; line-height: 1.5; margin-top: 0.5em; margin-bottom: 0.5em;">
              <li>The user will provide a task instruction along with a description of the scene in front of you.</li>  
              <li>Think about how you will complete the task by reasoning through how the object needs to be manipulated subject to the constraints of the robot's capabilities. When planning, take into account how a human might accomplish the task.</li>
              <li>Write down the steps you need to follow in detail to execute the full task. Each step should correspond to 1 API call and contain a description of how you expect the scene to look like after executing the step based on what the robot did. Specifically, describe how the state of the objects in the scene should be and change after executing each step. Pay close attention to the position and orientation of objects. <strong>DO NOT SKIP THIS STEP</strong>.</li>
              <li>Write python code to execute the steps on the robot using the API provided below.</li>
            </ol>
              The lines of code you write will be executed and the user will provide you with feedback after the code execution.
          <!-- </div> -->
          </p>

<pre style="max-height: 500px; overflow-y: auto; margin-top: 1em; max-width: 100%;">
<code class="language-python">class RobotAPI(object):
  def reset(self):
    '''
    Robot will reset, meaning it will open its gripper and return its arm to a retracted position.
    '''

  def grasp_object(self, object_name: str, grasp_approach: str):
    '''
    Robot will attempt to grasp the object using the approach specified in grasp_approach.
    Args:
      object_name: The name of the object to grasp. Objects should be referred to by some defining feature (e.g. color, brand, texture, etc.) and object type (e.g. cup, can, bowl, bag, etc.).
      grasp_approach: One of "top-down", "from the side" or "diagonally".
        "top-down" means the robot will descend from above the object and grasp. The object will be held with a vertical gripper orientation, with the fingers pointing down (i.e. 6pm on a clock).
        "from the side" means the robot will approach the object from the right side and grasp. The object will be held with the fingers oriented horizontally pointing to the left (i.e. 9pm on a clock).
        "diagonally" means the robot will approach the object neither perfectly top-down or from the side, the fingers will be pointed diagonally.
    '''

  def reorient(self, desired_gripper_orientation: str):
    '''
    Robot will attempt to reorient the object by turning its end-effector to the desired_gripper_orientation while maintaining its grasp on the object.
    If the robot's gripper is vertical and reorients 90 degrees to horizontal, the object will also be reoriented by 90 degrees clockwise.
    If the robot's gripper is horizontal and reorients 90 degrees to vertical, the object will also be reoriented by 90 degrees counterclockwise.
    Args:
      desired_gripper_orientation: One of "vertical" or "horizontal".
        "vertical" means having its fingers on the same plane, parallel to the left and right walls, pointing straight down (i.e. 6pm on a clock).
        "horizontal" means having its fingers on the same plane, parallel to the ground, and pointing to the left (i.e. 9pm on a clock).
    '''

  def place_object(self, object_name: str, location: str = "here"):
    '''
    Robot will attempt to place the object at the specified location.
    Args:
      object_name: The name of the object to place.
      location: One of "here", "left", "right", "front", "back", "center".
        Default is "here" meaning the robot will set the object straight down where the arm currently is, releasing it from its grasp.
        If one of [left/right/front/back], the robot will move the object to the specified edge (or center) and then release the object there.
    '''

  def lift_object(self, object_name: str):
    '''
    Robot will maintain its grasp on the object and lift it, maintaining the x-y position and orientation of the object.
    '''
</code>
</pre>

<h2 style="margin: 1em 0">Results</h2>

<!-- Task Output Container -->
<!-- increase width -->

<div class="task-container" id="exampleCarousel1" style="width: 100%;">
  <h3 style="margin: 1em 0">Task: Pick and hold up flower pot without disturbing the plant</h3>
  <!-- Carousel for task outputs -->
  <div class="example-carousel">
  <!-- Left arrow to navigate through examples -->
  <button class="carousel-button left" onclick="prevExample('exampleCarousel1')">&#10094;</button>
    <div class="example-track">
<!-- Example 1 -->
<div class="example-slide">
  <div class="example-left">
    <figure>
      <img src="assets/gemini_input/plant/1.png" alt="Example 1 Input Image">
      <figcaption>This is a picture of the scene. Please pick up the orange flower pot without disturbing the plant.</figcaption>
    </figure>
  </div>
  <div class="example-right">
<p>I see the orange flower pot and will pick it up carefully.</p>

<p>Here are the steps I will take:</p>

<ol>
<li><strong>Grasp object:</strong> I will grasp the orange flower pot from the side.
  <ul>
      <li><strong>Expected state:</strong> I will be grasping the orange flower pot from the side, lifting it slightly off the table.</li>
  </ul>
</li>
<li><strong>Lift object:</strong> I will lift the orange flower pot higher.
  <ul>
      <li><strong>Expected state:</strong> I will be holding the orange flower pot in the air.</li>
  </ul>
</li>
</ol>

<p>Here is the code:</p>

<pre style="overflow-wrap: anywhere;">
<code class="language-python">
robot_api.grasp_object(object_name="orange flower pot", grasp_approach="from the side")
robot_api.lift_object(object_name="orange flower pot") 
</code>
</pre>
  </div>
</div>

<!-- Example 2 -->
<div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/plant/2.png" alt="Example 2 Input Image">
    <figcaption>This is a picture of the scene. Please pick up the orange flower pot without disturbing the plant.</figcaption>
  </div>
  <div class="example-right">
<p>The pot is centered on the table. I will grab the pot from the side, lift it up, and hold.</p>

<p>Here are the steps to complete the task:</p>

<ol>
<li><strong>Grasp the pot:</strong> The robot will move its arm to the right side of the orange pot and grasp it from the side. The pot should now be held within the robot's gripper, with the gripper oriented horizontally (fingers pointing to the left).
  <pre style="overflow-wrap: anywhere;"><code class="language-python">robot_api.grasp_object(object_name='orange pot', grasp_approach='from the side')</code></pre>
</li>
<li><strong>Lift the pot:</strong> The robot will lift the pot straight up. The pot should now be in the air, still held in the robot's gripper.
  <pre style="overflow-wrap: anywhere;"><code class="language-python">robot_api.lift_object(object_name='orange pot')</code></pre>
</li>
</ol>

<p>That's it! I am now holding the orange pot.</p>
  </div>
</div>

<!-- Example 3 -->
<div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/plant/3.png" alt="Example 3 Input Image">
    <figcaption>This is a picture of the scene. Please pick up the orange flower pot without disturbing the plant.</figcaption>
  </div>
  <div class="example-right">
    <p>The flower pot appears to be made of clay and is centrally located on the table. I will approach the pot carefully from the top and grab it, making sure I do not touch the plant.</p>

    <p>Steps:</p>
    
    <ol>
        <li><strong>grasp_object("orange flower pot", "top-down")</strong>: The robot's gripper should now be grasping the orange flower pot from the top. The plant should remain undisturbed.</li>
        <li><strong>lift_object("orange flower pot")</strong>: The robot should now be holding up the orange flower pot, which is still being grasped by the gripper.</li>
    </ol>
    
    <pre style="overflow-wrap: anywhere;">
    <code class="language-python">robot_api.grasp_object("orange flower pot", "top-down")
    robot_api.lift_object("orange flower pot")
    </code>
    </pre>          
  </div>
</div>

<!-- Example 4 -->
<div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/plant/4.png" alt="Example 4 Input Image">
    <figcaption>This is a picture of the scene. Please pick up the orange flower pot without disturbing the plant.</figcaption>
  </div>
  <div class="example-right">
    <h2>Reasoning</h2>
    <p>The robot needs to grasp the flower pot from the side, as a top-down grasp would crush the plant. Once the pot is grasped, the robot can lift it up.</p>
    
    <h2>Steps:</h2>
    
    <ol>
        <li><strong>Grasp the pot:</strong> The robot will reach for the orange flower pot and grasp it from the side. After this step, the robot will be holding the flower pot with its gripper oriented horizontally.
            <pre style="overflow-wrap: anywhere;"><code class="language-python">robot_api.grasp_object(object_name="orange flower pot", grasp_approach="from the side")</code></pre>
        </li>
        <li><strong>Lift the pot:</strong> The robot will lift the flower pot upwards while maintaining its grasp. After this step, the robot will be holding the pot in the air.
            <pre style="overflow-wrap: anywhere;"><code class="language-python">robot_api.lift_object(object_name="orange flower pot")</code></pre>
        </li>
    </ol>
    
    <h2>Full Code:</h2>
    
    <pre style="overflow-wrap: anywhere;">
    <code class="language-python">robot_api.grasp_object(object_name="orange flower pot", grasp_approach="from the side")
    robot_api.lift_object(object_name="orange flower pot")
    </code>
    </pre>
    
  </div>
</div>

<!-- Example 5 -->
<div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/plant/5.png" alt="Example 5 Input Image">
    <figcaption>This is a picture of the scene. Please pick up the orange flower pot without disturbing the plant.</figcaption>
  </div>
  <div class="example-right">
    <p>The flower pot has a lip around the top, so I can grasp it from the outside. I will grasp the pot from the side, lift it slightly, then hold it up.</p>

    <p>Steps:</p>
    
    <ol>
        <li><strong>Grasp the pot:</strong> Grasp the orange flower pot from the side. The pot will be held in the robot's gripper with the fingers oriented horizontally.
            <pre style="overflow-wrap: anywhere;"><code class="language-python">robot_api.grasp_object(object_name="orange flower pot", grasp_approach="from the side")</code></pre>
        </li>
        <li><strong>Lift the pot:</strong> Lift the orange flower pot slightly. The pot will be elevated, but its orientation will remain the same.
            <pre style="overflow-wrap: anywhere;"><code class="language-python">robot_api.lift_object(object_name="orange flower pot")</code></pre>
        </li>
    </ol>
    
    <p>That's it! The robot should now be holding up the orange flower pot.</p>
    
  </div>
</div>


<!-- Example 6 -->
<div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/plant/6.png" alt="Example 6 Input Image">
    <figcaption>This is a picture of the scene. Please pick up the orange flower pot without disturbing the plant.</figcaption>
  </div>
  <div class="example-right">
    <p>The flower pot is centered on the table. I will grasp the pot from the side and lift it up.</p>

<p>Here are the steps to complete the task:</p>

<ol>
<li><strong>Grasp the pot:</strong> Grasp the orange flower pot from the side. The pot will now be in the robot's gripper.
  <pre style="overflow-wrap: anywhere;"><code class="language-python">robot_api.grasp_object(object_name='orange flower pot', grasp_approach='from the side')</code></pre>
</li>
<li><strong>Lift the pot:</strong> Lift the orange flower pot upwards. The pot will be lifted upwards while still being grasped by the robot.
  <pre style="overflow-wrap: anywhere;"><code class="language-python">robot_api.lift_object(object_name='orange flower pot')</code></pre>
</li>
</ol>
  </div>
</div>

<!-- Example 7 -->
<div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/plant/7.png" alt="Example 7 Input Image">
    <figcaption>This is a picture of the scene. Please pick up the orange flower pot without disturbing the plant.</figcaption>
  </div>
  <div class="example-right">
    <h2>Reasoning:</h2>
    <p>To pick up the flower pot without disturbing the plant, I need to grasp the pot firmly from the sides. Since I only have one arm, I cannot stabilize the plant from the top.</p>
    
    <h2>Steps:</h2>
    
    <ol>
        <li><strong>Grasp the flower pot:</strong> Approach the pot from the side and grasp it firmly.
            <ul>
                <li><strong>Expected state:</strong> The robot arm will be holding the flower pot from the side. The plant should remain undisturbed inside the pot. The gripper orientation will be horizontal.</li>
            </ul>
        </li>
        <li><strong>Lift the flower pot:</strong> Lift the pot vertically to hold it up.
            <ul>
                <li><strong>Expected state:</strong> The robot arm will be raised, holding the flower pot with the plant still inside.</li>
            </ul>
        </li>
    </ol>
    
    <h2>Python code:</h2>
    
    <pre style="overflow-wrap: anywhere;">
    <code class="language-python">robot_api.grasp_object(object_name="orange flower pot", grasp_approach="from the side")
    robot_api.lift_object(object_name="orange flower pot")
    </code>
    </pre>
    
  </div>
</div>

<!-- Example 8 -->
<div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/plant/8.png" alt="Example 8 Input Image">
    <figcaption>This is a picture of the scene. Please pick up the orange flower pot without disturbing the plant.</figcaption>
  </div>
  <div class="example-right">
    <p>The robot should grasp the orange pot from the sides and lift it up.</p>

    <p>Here are the steps to complete the task:</p>
    
    <ol>
        <li><strong>Grasp object:</strong> The robot will grasp the orange flower pot from the side. The gripper will be oriented horizontally.
            <pre style="overflow-wrap: anywhere;"><code class="language-python">robot_api.grasp_object(object_name='orange flower pot', grasp_approach='from the side')</code></pre>
        </li>
        <li><strong>Lift object:</strong> The robot will then lift the pot upwards. The pot will be lifted with the gripper in a horizontal orientation.
            <pre style="overflow-wrap: anywhere;"><code class="language-python">robot_api.lift_object(object_name='orange flower pot')</code></pre>
        </li>
    </ol>
    
    <p>That's it! Let me know how it goes.</p>          
  </div>
</div>

<!-- Example 9 -->
<div class="example-slide">
<div class="example-left">
  <img src="assets/gemini_input/plant/9.png" alt="Example 9 Input Image">
  <figcaption>This is a picture of the scene. Please pick up the orange flower pot without disturbing the plant.</figcaption>
</div>
<div class="example-right">
  <p>The robot should grasp the pot from the sides and lift it up.</p>

  <p>Here are the steps:</p>
  
  <ol>
      <li><strong>Grasp the orange flower pot:</strong> The robot will move its arm to the flower pot and grasp it from the sides. The gripper fingers will be oriented horizontally (9pm on a clock) and will be squeezing the sides of the pot.</li>
      <li><strong>Lift the pot:</strong> The robot will lift the pot straight up, keeping the pot level.</li>
  </ol>
  
  <pre style="overflow-wrap: anywhere;">
  <code class="language-python">robot_api.grasp_object(object_name='orange flower pot', grasp_approach='from the side')
  robot_api.lift_object(object_name='orange flower pot')
  </code>
  </pre>                
</div>
</div>


<!-- Example 10 -->
<div class="example-slide">
<div class="example-left">
  <img src="assets/gemini_input/plant/10.png" alt="Example 10 Input Image">
  <figcaption>This is a picture of the scene. Please pick up the orange flower pot without disturbing the plant.</figcaption>
</div>
<div class="example-right">
  <h2>Reasoning</h2>
  <p>The robot should be able to grasp the orange flower pot from the sides and lift it up.</p>
  
  <h2>Steps:</h2>
  
  <ol>
      <li><strong>Grasp Object:</strong> Grasp the orange flower pot from the side. The gripper's fingers should be oriented horizontally.
          <ul>
              <li><strong>Expected state:</strong> The robot is now grasping the orange flower pot from the sides.</li>
          </ul>
      </li>
      <li><strong>Lift Object:</strong> Lift the orange flower pot up.
          <ul>
              <li><strong>Expected state:</strong> The robot is now holding the orange flower pot in the air.</li>
          </ul>
      </li>
  </ol>
  
  <h2>Python Code:</h2>
  
  <pre style="overflow-wrap: anywhere;">
  <code class="language-python">robot_api.grasp_object(object_name="orange flower pot", grasp_approach="from the side")
  robot_api.lift_object(object_name="orange flower pot")
  </code>
  </pre>           
</div>
</div>

    </div>

  <!-- Right arrow to navigate through examples -->
  <button class="carousel-button right" onclick="nextExample('exampleCarousel1')">&#10095;</button>
  </div>


  <div class="task-container" id="exampleCarousel2" style="width: 100%;">
    <h3 style="margin: 1em 0">Task: Hold the fruit up, while avoiding the other objects</h3>

    <!-- Carousel for task outputs -->
    <div class="example-carousel">
    <!-- Left arrow to navigate through examples -->
    <button class="carousel-button left" onclick="prevExample('exampleCarousel2')">&#10094;</button>
      <div class="example-track">
        <!-- Example 1 -->
        <div class="example-slide">
          <div class="example-left">
            <img src="assets/gemini_input/fruit/1.png" alt="Example 1 Input Image">
            <figcaption>This is a picture of the scene. Hold the apple up, while avoiding the other objects.</figcaption>
        </div>
          <div class="example-right">
            <p>The apple is in the center of the table, with a few plants surrounding it. I will grasp the apple from the top and lift it up.</p>

            <p>Here are the steps to complete the task:</p>
            
            <ol>
                <li><strong>Grasp the apple:</strong> The robot will move its arm to the center of the table, open its gripper, lower the gripper until it's around the apple, and then close the gripper. The apple should now be in the robot's grasp.
                    <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name='red apple', grasp_approach='top-down')</code></pre>
                </li>
                <li><strong>Lift the apple:</strong> The robot will move its arm upwards, lifting the apple off the table. The apple should now be raised above the table, held by the robot.
                    <pre style="overflow-wrap: anywhere;"><code>robot_api.lift_object(object_name='red apple')</code></pre>
                </li>
            </ol>
            
            <p>That's it! The apple should now be held up by the robot.</p>
            
          </div>
        </div>
    
        <!-- Example 2 -->
        <div class="example-slide">
          <div class="example-left">
            <img src="assets/gemini_input/fruit/2.png" alt="Example 2 Input Image">
            <figcaption>This is a picture of the scene. Hold the grapes up, while avoiding the other objects.</figcaption>
          </div>
          <div class="example-right">
            <p>The grapes are in the center of the table, with a plant in a white pot to the left and a plant in an orange pot to the right.</p>

            <p>Here are the steps to complete the task:</p>
            
            <ol>
                <li><strong>Grasp grapes:</strong> Reach towards the grapes from above and grasp them.
                    <ul>
                        <li><strong>Expected state:</strong> The robot's gripper is grasping the grapes. All other objects remain in their initial positions.</li>
                    </ul>
                </li>
                <li><strong>Lift grapes:</strong> Lift the grapes straight up.
                    <ul>
                        <li><strong>Expected state:</strong> The robot is holding the grapes in the air. All other objects remain in their initial positions.</li>
                    </ul>
                </li>
            </ol>
            
            <pre style="overflow-wrap: anywhere;">
            <code>robot_api.grasp_object(object_name='grapes', grasp_approach='top-down')
            robot_api.lift_object(object_name='grapes')
            </code>
            </pre>
            
          </div>
        </div>
  
        <!-- Example 3 -->
        <div class="example-slide">
          <div class="example-left">
            <img src="assets/gemini_input/fruit/3.png" alt="Example 3 Input Image">
            <figcaption>This is a picture of the scene. Hold the orange up, while avoiding the other objects.</figcaption>
          </div>
          <div class="example-right">
            <h2>Reasoning:</h2>
<p>To hold the orange up, I need to grasp it and then lift it. Since my gripper is large, I need to make sure to approach the orange carefully to avoid hitting the nearby plants. A top-down grasp would be best to ensure a stable grip.</p>

<h2>Steps:</h2>

<ol>
    <li><strong>Grasp the orange:</strong> Reach for the orange from above and grasp it.
        <ul>
            <li><strong>Expected state:</strong> The robot's gripper is grasping the orange. All other objects remain in their original positions.</li>
        </ul>
    </li>
    <li><strong>Lift the orange:</strong> Lift the orange upwards.
        <ul>
            <li><strong>Expected state:</strong> The robot is holding the orange in the air. All other objects remain in their original positions.</li>
        </ul>
    </li>
</ol>

<h2>Code:</h2>

<pre style="overflow-wrap: anywhere;">
<code>robot_api.grasp_object(object_name="orange", grasp_approach="top-down")
robot_api.lift_object(object_name="orange")
</code>
</pre>      
          </div>
        </div>
 <!-- Example 4 -->
 <div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/fruit/4.png" alt="Example 4 Input Image">
    <figcaption>This is a picture of the scene. Hold the apple up, while avoiding the other objects.</figcaption>
  </div>
  <div class="example-right">
    <h2>Reasoning:</h2>
    <p>The robot should grasp the apple from the top and lift it up.</p>

    <p>Here are the steps to complete the task:</p>
    
    <ol>
        <li><strong>Grasp the apple:</strong> The robot will reach for the apple from the top and grasp it. The apple will now be in the robot's gripper.
            <ul>
                <li>Code: <code>robot_api.grasp_object(object_name="red apple", grasp_approach="top-down")</code></li>
            </ul>
        </li>
        <li><strong>Lift the apple:</strong> The robot will lift the apple up. The apple will be lifted vertically, maintaining its orientation.
            <ul>
                <li>Code: <code>robot_api.lift_object(object_name="red apple")</code></li>
            </ul>
        </li>
    </ol>
    
    <p>Let me know if you would like to proceed with the execution.</p>    
  </div>
</div>

 <!-- Example 5 -->
 <div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/fruit/5.png" alt="Example 5 Input Image">
    <figcaption>This is a picture of the scene. Hold the orange up, while avoiding the other objects.</figcaption>
  </div>
  <div class="example-right">
    <h2>Reasoning:</h2>
<p>To hold the orange up, I need to grasp it and then lift it. Since I only have one arm, I need to make sure the grasp is secure before lifting. A top-down grasp is best for this. I also need to make sure I don’t knock over the plants on either side of the orange.</p>

<h2>Steps:</h2>

<ol>
    <li><strong>Grasp the orange:</strong> Reach for the orange from above and grasp it.
        <ul>
            <li><strong>Expected state:</strong> The robot arm is holding the orange with a vertical gripper orientation. The orange is no longer on the table.</li>
        </ul>
    </li>
    <li><strong>Lift the orange:</strong> Lift the orange upwards.
        <ul>
            <li><strong>Expected state:</strong> The robot arm is holding the orange in the air. The orange is no longer touching the table.</li>
        </ul>
    </li>
</ol>

<h2>Code:</h2>

<pre style="overflow-wrap: anywhere;">
<code>robot_api.grasp_object(object_name='orange', grasp_approach='top-down')
robot_api.lift_object(object_name='orange')
</code>
</pre>
  </div>
</div>

 <!-- Example 6 -->
 <div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/fruit/6.png" alt="Example 6 Input Image">
    <figcaption>This is a picture of the scene. Hold the grapes up, while avoiding the other objects.</figcaption>
  </div>
  <div class="example-right">
    <p>I see the bunch of grapes in the center of the table, between the three white pots to the left and the white pot to the right. I will grasp the grapes from the top and lift them up.</p>

<p>Here are the steps to complete this task:</p>

<ol>
    <li><strong>Grasp the grapes:</strong> The grapes are in the center of the table. I will grasp them from the top.
        <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name="grapes", grasp_approach="top-down")</code></pre>
        <p>After this step, the robot will be grasping the grapes with its gripper oriented vertically, the fingers pointing down.</p>
    </li>
    <li><strong>Lift the grapes:</strong> I will lift the grapes up to hold them up.
        <pre style="overflow-wrap: anywhere;"><code>robot_api.lift_object(object_name="grapes")</code></pre>
        <p>After this step, the robot will be holding the grapes in the air. All other objects will remain in their initial state.</p>
    </li>
</ol>
  </div>
</div>

 <!-- Example 7 -->
 <div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/fruit/7.png" alt="Example 7 Input Image">
    <figcaption>This is a picture of the scene. Hold the apple up, while avoiding the other objects.</figcaption>
  </div>
  <div class="example-right">
    <h2>Reasoning:</h2>
    <p>To hold the apple up, I need to grasp it and then lift it. Since the apple is unobstructed from the top, a top-down grasp is best.</p>
    
    <h2>Steps:</h2>
    
    <ol>
        <li><strong>Grasp the apple:</strong> The robot should grasp the apple from the top.
            <ul>
                <li><strong>Expected state:</strong> The robot is now grasping the apple with its gripper oriented vertically. The apple is no longer resting on the table.</li>
            </ul>
        </li>
        <li><strong>Lift the apple:</strong> The robot should lift the apple upwards.
            <ul>
                <li><strong>Expected state:</strong> The robot is now holding the apple in the air. All other objects remain in their original positions.</li>
            </ul>
        </li>
    </ol>
    
    <h2>Code:</h2>
    
    <pre style="overflow-wrap: anywhere;">
    <code>robot_api.grasp_object(object_name='red apple', grasp_approach='top-down')
    robot_api.lift_object(object_name='red apple')
    </code>
    </pre>    
  </div>
</div>

 <!-- Example 8 -->
 <div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/fruit/8.png" alt="Example 8 Input Image">
    <figcaption>This is a picture of the scene. Hold the orange up, while avoiding the other objects.</figcaption>
  </div>
  <div class="example-right">
    <p>The orange is in the center of the table, with two plants on either side of it and two gardening tools in front of it. To complete this task, I will grasp the orange from the top, lift it up, and hold it there.</p>

<p>Here are the steps I will take:</p>

<ol>
    <li><strong>Grasp the orange:</strong> I will grasp the orange from the top. The orange will now be in the robot's gripper.
        <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name='orange', grasp_approach='top-down')</code></pre>
    </li>
    <li><strong>Lift the orange:</strong> I will lift the orange up. The orange will now be held above the table, with the gripper still oriented vertically.
        <pre style="overflow-wrap: anywhere;"><code>robot_api.lift_object(object_name='orange')</code></pre>
    </li>
</ol>
  </div>
</div>

 <!-- Example 9 -->
 <div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/fruit/9.png" alt="Example 9 Input Image">
    <figcaption>This is a picture of the scene. Hold the grapes up, while avoiding the other objects.</figcaption>
  </div>
  <div class="example-right">
    <h2>Reasoning:</h2>
    <p>To hold the grapes up, I need to grasp them and then lift my arm. Since I only have one arm, I need to make sure the grapes are the only object in my grasp. To avoid hitting the plants or the tools, I should approach the grapes from the side.</p>
    
    <h2>Steps:</h2>
    
    <ol>
        <li><strong>Grasp the grapes:</strong> Reach for the grapes from the side and grasp them.
            <ul>
                <li><strong>Expected state:</strong> The robot's gripper should be holding the grapes, with the fingers oriented horizontally. The grapes should be lifted slightly off the table. All other objects remain untouched.</li>
            </ul>
        </li>
        <li><strong>Lift the grapes:</strong> Raise the arm holding the grapes.
            <ul>
                <li><strong>Expected state:</strong> The robot arm is raised with the grapes held in a horizontal orientation by the gripper. All other objects remain untouched.</li>
            </ul>
        </li>
    </ol>
    
    <h2>Code:</h2>
    
    <pre style="overflow-wrap: anywhere;">
    <code>robot_api.grasp_object(object_name='grapes', grasp_approach='from the side')
    robot_api.lift_object(object_name='grapes')
    </code>
    </pre>
  </div>
</div>

 <!-- Example 10 -->
 <div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/fruit/10.png" alt="Example 10 Input Image">
    <figcaption>This is a picture of the scene. Hold the apple up, while avoiding the other objects.</figcaption>
  </div>
  <div class="example-right">
    <h2>Reasoning:</h2>
    <p>To hold the apple up, I need to grasp it and then lift it. I will use a top-down grasp to pick up the apple directly.</p>
    
    <h2>Steps:</h2>
    
    <ol>
        <li><strong>Grasp the apple:</strong> Reach for the apple from above and grasp it.
            <ul>
                <li><strong>Expected state:</strong> The robot's gripper is grasping the apple. All other objects remain in their original positions.</li>
            </ul>
        </li>
        <li><strong>Lift the apple:</strong> Lift the apple straight up.
            <ul>
                <li><strong>Expected state:</strong> The robot is holding the apple in the air. All other objects remain in their original positions.</li>
            </ul>
        </li>
    </ol>
    
    <h2>Code:</h2>
    
    <pre style="overflow-wrap: anywhere;">
    <code>robot_api.grasp_object(object_name='red apple', grasp_approach='top-down')
    robot_api.lift_object(object_name='red apple')
    </code>
    </pre>    
  </div>
</div>

 <!-- Example 11 -->
 <div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/fruit/11.png" alt="Example 11 Input Image">
    <figcaption>This is a picture of the scene. Hold the orange up, while avoiding the other objects.</figcaption>
  </div>
  <div class="example-right">
    <p>The robot should grasp the orange from the top and lift it up while avoiding the other objects.</p>

<h2>Steps:</h2>
<ol>
    <li>
        <strong>Grasp the orange:</strong> The robot will move its arm to be above the orange and grasp it from the top. The orange should now be in the robot's gripper.
        <ul>
            <li><strong>Code:</strong> <code>robot_api.grasp_object(object_name="orange", grasp_approach="top-down")</code></li>
            <li><strong>Expected state:</strong> The orange is now grasped by the robot's gripper. All other objects remain in their original positions.</li>
        </ul>
    </li>
    <li>
        <strong>Lift the orange:</strong> The robot will lift the orange straight up.
        <ul>
            <li><strong>Code:</strong> <code>robot_api.lift_object(object_name="orange")</code></li>
            <li><strong>Expected state:</strong> The orange is now raised above the table, held by the robot. All other objects remain in their original positions.</li>
        </ul>
    </li>
</ol>
  
  </div>
</div>

 <!-- Example 12 -->
 <div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/fruit/12.png" alt="Example 12 Input Image">
    <figcaption>This is a picture of the scene. Hold the grapes up, while avoiding the other objects.</figcaption>
  </div>
  <div class="example-right">
    <p>The grapes are in the center of the table, with a kettle to the left, a whisk to the right, and a mug at the top. The drawer is currently closed.</p>

    <h2>Here are the steps to complete the task:</h2>
    
    <ol>
        <li>
            <strong>Grasp the grapes:</strong> Reach for the grapes from above and grasp them.
            <ul>
                <li><strong>Expected state:</strong> The robot's gripper is grasping the grapes. All other objects remain in their initial positions.</li>
            </ul>
        </li>
        <li>
            <strong>Lift the grapes:</strong> Lift the grapes straight up.
            <ul>
                <li><strong>Expected state:</strong> The robot is holding the grapes in the air. All other objects remain in their initial positions.</li>
            </ul>
        </li>
    </ol>
    
    <h2>Code:</h2>
    
    <pre style="overflow-wrap: anywhere;">
    <code>robot_api.grasp_object(object_name='grapes', grasp_approach='top-down')
    robot_api.lift_object(object_name='grapes')
    </code>
    </pre>
      
  </div>
</div>

<!-- Example 13 -->
<div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/fruit/13.png" alt="Example 13 Input Image">
    <figcaption>This is a picture of the scene. Hold the apple up, while avoiding the other objects.</figcaption>
  </div>
  <div class="example-right">
    <h2>Reasoning:</h2>
    <p>The apple is in the center of the table, surrounded by other objects. To grasp it, the robot needs to approach from the top to avoid collisions. Once grasped, the apple needs to be lifted to be considered "held up".</p>
    
    <h2>Steps:</h2>
    <ol>
        <li>
            <strong>Grasp apple:</strong> The robot will move its arm to the apple and grasp it from the top.
            <ul>
                <li><strong>Expected state:</strong> The robot is now grasping the apple with its gripper oriented vertically. All other objects remain in their original positions.</li>
            </ul>
        </li>
        <li>
            <strong>Lift apple:</strong> The robot will lift the apple while maintaining its grasp.
            <ul>
                <li><strong>Expected state:</strong> The apple is now raised above the table, held by the robot. All other objects remain in their original positions.</li>
            </ul>
        </li>
    </ol>
    
    <h2>Code:</h2>
    <pre style="overflow-wrap: anywhere;">
    <code>robot_api.grasp_object(object_name="red apple", grasp_approach="top-down")
    robot_api.lift_object(object_name="red apple")</code>
    </pre>    
  </div>
</div>

<!-- Example 14 -->
<div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/fruit/14.png" alt="Example 14 Input Image">
    <figcaption>This is a picture of the scene. Hold the orange up, while avoiding the other objects.</figcaption>
  </div>
  <div class="example-right">

    <p>The orange is in the center of the table, surrounded by plants and gardening tools. I will grasp the orange from the top and lift it up.</p>

    <h2>Steps to Complete the Task:</h2>
    
    <ol>
        <li>
            <strong>Grasp orange:</strong> Grasp the orange from the top. The gripper will be oriented vertically.
            <ul>
                <li><strong>Expected state:</strong> The robot's gripper will be grasping the orange.</li>
            </ul>
        </li>
        <li>
            <strong>Lift orange:</strong> Lift the orange up.
            <ul>
                <li><strong>Expected state:</strong> The robot will be holding the orange in the air.</li>
            </ul>
        </li>
    </ol>
    
    <h2>Python Code:</h2>
    <pre style="overflow-wrap: anywhere;">
    <code>robot_api.grasp_object(object_name='orange', grasp_approach='top-down')
    robot_api.lift_object(object_name='orange')</code>
    </pre> 
  </div>
</div>

<!-- Example 15 -->
<div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/fruit/15.png" alt="Example 15 Input Image">
    <figcaption>This is a picture of the scene. Hold the grapes up, while avoiding the other objects.</figcaption>
  </div>
  <div class="example-right">
    <h2>Reasoning:</h2>
    <p>To hold the grapes up, I need to grasp them and then lift them. Since the grapes are in the middle of the table, I need to make sure to grasp them from the top to avoid hitting other objects.</p>
    
    <h2>Steps:</h2>
    <ol>
        <li>
            <strong>Grasp the grapes:</strong> Reach for the grapes from the top and grasp them.
            <ul>
                <li><strong>Expected state:</strong> The robot's gripper is grasping the grapes. All other objects remain in their original positions.</li>
            </ul>
        </li>
        <li>
            <strong>Lift the grapes:</strong> Lift the grapes vertically.
            <ul>
                <li><strong>Expected state:</strong> The robot is holding the grapes in the air. All other objects remain in their original positions.</li>
            </ul>
        </li>
    </ol>
    
    <h2>Code:</h2>
    <pre style="overflow-wrap: anywhere;">
    <code>robot_api.grasp_object(object_name="grapes", grasp_approach="top-down")
    robot_api.lift_object(object_name="grapes")</code>
    </pre>    
  </div>
</div>
      </div>

  <!-- Right arrow to navigate through examples -->
  <button class="carousel-button right" onclick="nextExample('exampleCarousel2')">&#10095;</button>
  </div>

  <div class="task-container" id="exampleCarousel3" style="width: 100%;">
    <h3 style="margin: 1em 0">Task: Pick and hold up the black and white kettle </h3>

    <!-- Carousel for task outputs -->
    <div class="example-carousel">
    <!-- Left arrow to navigate through examples -->
    <button class="carousel-button left" onclick="prevExample('exampleCarousel3')">&#10094;</button>
      <div class="example-track">
        <!-- Example 1 -->
        <div class="example-slide">
          <div class="example-left">
            <figure>
              <img src="assets/gemini_input/kettle/1.png" alt="Example 1 Input Image">
              <figcaption>This is a picture of the scene. Please pick and hold up the black and white kettle.</figcaption>
            </figure>
          </div>
          <div class="example-right">
            <p>The kettle appears to be upright with its handle oriented to the left.</p>

<p>Here are the steps to pick up the kettle:</p>
<ol>
    <li>
        <strong>Grasp the kettle:</strong> The robot will grasp the kettle from the top. After this step, the kettle will be held by the robot with the gripper oriented vertically.
        <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name='white kettle with black handle', grasp_approach='top-down')</code></pre>
    </li>
    <li>
        <strong>Lift the kettle:</strong> The robot will lift the kettle upwards. After this step, the kettle will be held up in the air by the robot.
        <pre style="overflow-wrap: anywhere;"><code>robot_api.lift_object(object_name='white kettle with black handle')</code></pre>
    </li>
</ol>

<p>Let me know how I did!</p>

          </div>
        </div>
    
<!-- Example 2 -->
<div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/kettle/2.png" alt="Example 2 Input Image">
    <figcaption>This is a picture of the scene. Please pick and hold up the black and white kettle.</figcaption>
  </div>
  <div class="example-right">
    <ol>
      <li>
          <strong>Grasp Kettle:</strong> The robot should grasp the kettle from the top since the handle is upright.
          <ul>
              <li><strong>State Change:</strong> The robot's gripper will be grasping the black and white kettle. The kettle will be lifted slightly off the table.</li>
          </ul>
      </li>
      <li>
          <strong>Lift Kettle:</strong> Lift the kettle to show that it is holding it.
          <ul>
              <li><strong>State Change:</strong> The robot's arm will be raised with the kettle held in the gripper. The kettle will be clear of the table.</li>
          </ul>
      </li>
  </ol>
  
  <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name='black and white kettle', grasp_approach='top-down')
  robot_api.lift_object(object_name='black and white kettle')</code></pre>          
  </div>
</div>
  
  <!-- Example 3 -->
  <div class="example-slide">
    <div class="example-left">
      <img src="assets/gemini_input/kettle/3.png" alt="Example 3 Input Image">
      <figcaption>This is a picture of the scene. Please pick and hold up the black and white kettle.</figcaption>
    </div>
    <div class="example-right">
      <p>The robot can complete this task. Here are the steps to pick up the kettle:</p>

      <ol>
          <li>
              <strong>Grasp the kettle:</strong> The robot will grasp the kettle from the top. After this step, the kettle will be held in the robot's gripper.
              <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name="black and white kettle", grasp_approach="top-down")</code></pre>
          </li>
          <li>
              <strong>Lift the kettle:</strong> The robot will lift the kettle upwards. After this step, the kettle will be held in the air.
              <pre style="overflow-wrap: anywhere;"><code>robot_api.lift_object(object_name="black and white kettle")</code></pre>
          </li>
      </ol>
  
      <p>Let me know when you would like me to proceed.</p>
    </div>
  </div>

 <!-- Example 4 -->
 <div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/kettle/4.png" alt="Example 4 Input Image">
    <figcaption>This is a picture of the scene. Please pick and hold up the black and white kettle.</figcaption>
  </div>
  <div class="example-right">
    <p>The kettle is sitting on the table. My end-effector is also above the table, so I can reach down to grasp it from the top and lift it up to hold it.</p>

    <p>Here are the steps to complete the task:</p>
    
    <ol>
        <li>
            <strong>Grasp the kettle:</strong> Grasp the "black and white kettle" from the top. The gripper will be oriented vertically with the kettle grasped in its middle.
        </li>
        <li>
            <strong>Lift the kettle:</strong> Lift the kettle straight up. The kettle will be lifted above the table and the gripper orientation will remain vertical.
        </li>
    </ol>
    
    <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name="black and white kettle", grasp_approach="top-down")
    robot_api.lift_object(object_name="black and white kettle")</code></pre>    
  </div>
</div>

 <!-- Example 5 -->
 <div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/kettle/5.png" alt="Example 5 Input Image">
    <figcaption>This is a picture of the scene. Please pick and hold up the black and white kettle.</figcaption>
  </div>
  <div class="example-right">
    <p>The kettle is sitting upright on the table. I will grasp the kettle from the top and lift it up.</p>

    <p>Here are the steps I will take:</p>
    
    <ol>
        <li>
            <strong>Grasp the kettle:</strong> I will move my arm to be above the kettle and orient my gripper to be vertical. Then I will grasp the kettle from the top.
            <ul>
                <li><strong>Object State:</strong> The kettle will be held in the robot's gripper.</li>
            </ul>
        </li>
        <li>
            <strong>Lift the kettle:</strong> I will lift the kettle straight up.
            <ul>
                <li><strong>Object State:</strong> The kettle will be held in the robot's gripper above the table.</li>
            </ul>
        </li>
    </ol>
    
    <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name='black and white kettle', grasp_approach='top-down')
    robot_api.lift_object(object_name='black and white kettle')</code></pre>    
  </div>
</div>

 <!-- Example 6 -->
 <div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/kettle/6.png" alt="Example 6 Input Image">
    <figcaption>This is a picture of the scene. Please pick and hold up the black and white kettle.</figcaption>
  </div>
  <div class="example-right">
    <p>The kettle's handle is sticking up, so it would be easiest to grasp the kettle from the side and then reorient to have the handle upright.</p>

    <p>Steps:</p>
    
    <ol>
        <li><code>grasp_object(object_name="black and white kettle", grasp_approach="from the side")</code>: The robot will move its arm to the kettle and grasp the body of it from the side. The kettle's handle will be horizontal, and spout facing forward.</li>
        <li><code>reorient(desired_gripper_orientation="vertical")</code>: The robot will maintain its grasp on the kettle and rotate its gripper to be vertical. The kettle will now be held upright with the spout facing to the right and handle to the back.</li>
        <li><code>lift_object(object_name="black and white kettle")</code>: The robot will lift the kettle straight up, maintaining the kettle's orientation.</li>
    </ol>
    
    <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name="black and white kettle", grasp_approach="from the side")
    robot_api.reorient(desired_gripper_orientation="vertical")
    robot_api.lift_object(object_name="black and white kettle")</code></pre>
    
  </div>
</div>

 <!-- Example 7 -->
 <div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/kettle/7.png" alt="Example 7 Input Image">
    <figcaption>This is a picture of the scene. Please pick and hold up the black and white kettle.</figcaption>
  </div>
  <div class="example-right">
    <p>The kettle is sitting upright on a table. I will grasp the kettle from the top, then I will lift it up.</p>

    <p>Here are the steps:</p>
    
    <ol>
        <li><strong>Grasp the kettle:</strong> I will grasp the kettle from the top with a vertical gripper orientation. The kettle will now be in the robot's gripper.</li>
        <li><strong>Lift the kettle:</strong> I will lift the kettle straight up, maintaining its grasp and orientation. The kettle will now be elevated above the table and grasped by the robot.</li>
    </ol>
    
    <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name="black and white kettle", grasp_approach="top-down")
    robot_api.lift_object(object_name="black and white kettle") 
    </code></pre>
    
  </div>
</div>

 <!-- Example 8 -->
 <div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/kettle/8.png" alt="Example 8 Input Image">
    <figcaption>This is a picture of the scene. Please pick and hold up the black and white kettle.</figcaption>
  </div>
  <div class="example-right">
    <h2>Reasoning:</h2>
    <p>The robot needs to grasp the kettle from above and lift it up.</p>
    
    <h2>Steps:</h2>
    <ol>
        <li><strong>Grasp the kettle:</strong> The robot will move its arm to be above the kettle and grasp it from the top.
            <ul>
                <li><strong>Expected state:</strong> The robot's gripper will be grasping the kettle with a vertical orientation (fingers pointing down).</li>
            </ul>
        </li>
        <li><strong>Lift the kettle:</strong> The robot will maintain its grasp on the kettle and lift it up.
            <ul>
                <li><strong>Expected state:</strong> The robot will be holding the kettle in the air.</li>
            </ul>
        </li>
    </ol>
    
    <h2>Code:</h2>
    <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name='black and white kettle', grasp_approach='top-down')
    robot_api.lift_object(object_name='black and white kettle') 
    </code></pre>    
  </div>
</div>

 <!-- Example 9 -->
 <div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/kettle/9.png" alt="Example 9 Input Image">
    <figcaption>This is a picture of the scene. Please pick and hold up the black and white kettle.</figcaption>
  </div>
  <div class="example-right">
    <p>The robot should be able to grasp the kettle from the top and lift it up.</p>

    <h2>Steps:</h2>
    <ol>
        <li><strong>Grasp the kettle:</strong> The robot will move its arm to be positioned above the "black and white kettle" and then grasp the kettle with a top-down grasp. The kettle will now be in the robot's gripper.</li>
        <li><strong>Lift the kettle:</strong> The robot will lift the kettle straight up, maintaining its grasp on the kettle. The kettle will now be raised above the table.</li>
    </ol>
    
    <h2>Code:</h2>
    <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name="black and white kettle", grasp_approach="top-down")
    robot_api.lift_object(object_name="black and white kettle")
    </code></pre>    
  </div>
</div>

 <!-- Example 10 -->
 <div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/kettle/10.png" alt="Example 10 Input Image">
    <figcaption>This is a picture of the scene. Please pick and hold up the black and white kettle.</figcaption>
  </div>
  <div class="example-right">
    <h2>Reasoning:</h2>
    <p>The robot needs to grasp the kettle from the top and lift it up. The handle orientation doesn't matter since the task is just to hold it up.</p>
    
    <h2>Steps:</h2>
    <ol>
        <li><strong>Grasp the kettle:</strong>  
            <ul>
                <li>Action: <code>grasp_object("black and white kettle", "top-down")</code></li>
                <li>Expected State: The robot will move its arm to the kettle, grasp it from the top, and the gripper fingers will be oriented vertically.</li>
            </ul>
        </li>
        <li><strong>Lift the kettle:</strong>
            <ul>
                <li>Action: <code>lift_object("black and white kettle")</code></li>
                <li>Expected State: The robot will maintain its grasp on the kettle and lift it slightly above the table. The kettle will remain in the same orientation as it was grasped.</li>
            </ul>
        </li>
    </ol>
    
    <h2>Code:</h2>
    <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object("black and white kettle", "top-down")
    robot_api.lift_object("black and white kettle")
    </code></pre>    
  </div>
</div>
</div>

<!-- Right arrow to navigate through examples -->
<button class="carousel-button right" onclick="nextExample('exampleCarousel3')">&#10095;</button>
</div>


<div class="task-container" id="exampleCarousel4" style="width: 100%;">
  <h3 style="margin: 1em 0">Task: Pour</h3>

  <!-- Carousel for task outputs -->
  <div class="example-carousel">
  <!-- Left arrow to navigate through examples -->
  <button class="carousel-button left" onclick="prevExample('exampleCarousel4')">&#10094;</button>
    <div class="example-track">

<!-- Example 1 -->
<div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/pouring/1.png" alt="Example 1 Input Image">
    <figcaption>This is a picture of the scene. Please pour contents out of the pink cup and place it back upright on the table.</figcaption>
  </div>
  <div class="example-right">
    <p>Sounds good, I can help with that! I will carefully grasp the pink cup, tilt it over so that the contents fall out, and then place the cup back on the table upright. Here are the steps I will take:</p>
    
    <ol>
        <li><strong>Grasp cup:</strong> I will grasp the pink cup from the side. 
            <ul>
                <li><strong>State change:</strong> The robot arm will move to the pink cup and grasp it from the side with its gripper oriented horizontally.</li>
            </ul>
        </li>
        <li><strong>Lift cup:</strong> I will lift the pink cup up.
            <ul>
                <li><strong>State change:</strong> The pink cup will be lifted up, off of the table.</li>
            </ul>
        </li>
        <li><strong>Reorient cup:</strong> I will reorient the cup so that the opening is facing down.
            <ul>
                <li><strong>State change:</strong> The robot arm will rotate its gripper so that it is oriented vertically. The pink cup will be rotated so that its opening is facing the table.</li>
            </ul>
        </li>
        <li><strong>Pour contents:</strong> I will move the cup over the table and shake it until the contents fall out.
            <ul>
                <li><strong>State change:</strong> The contents of the pink cup will be emptied onto the table.</li>
            </ul>
        </li>
        <li><strong>Reorient cup:</strong> I will reorient the cup so the opening is facing up.
            <ul>
                <li><strong>State change:</strong> The robot arm will rotate its gripper so that it is oriented horizontally. The pink cup will be rotated so that its opening is facing up.</li>
            </ul>
        </li>
        <li><strong>Place cup:</strong> I will place the cup back on the table.
            <ul>
                <li><strong>State change:</strong> The robot arm will move the pink cup back down to the table and release it. The pink cup will be upright on the table.</li>
            </ul>
        </li>
    </ol>
    
    <h2>Code:</h2>
    <pre style="overflow-wrap: anywhere;">
      <code>
        robot_api.grasp_object(object_name='pink cup', grasp_approach='from the side')
        robot_api.lift_object(object_name='pink cup')
        robot_api.reorient(desired_gripper_orientation='vertical')
        # Since there is no shake function in the API, we can try to achieve the desired outcome by reorienting the gripper back and forth.
        robot_api.reorient(desired_gripper_orientation='horizontal')
        robot_api.reorient(desired_gripper_orientation='vertical')
        robot_api.reorient(desired_gripper_orientation='horizontal') 
        robot_api.place_object(object_name='pink cup', location='here')
      </code>
    </pre>
    
  </div>
</div>

<!-- Example 2 -->
<div class="example-slide">
  <div class="example-left">
    <img src="assets/gemini_input/pouring/2.png" alt="Example 2 Input Image">
    <figcaption>This is a picture of the scene. Please pour contents out of the pink cup and place it back upright on the table.</figcaption>
  </div>
  <div class="example-right">
    <h2>Reasoning:</h2>
    <p>To pour the contents of the pink cup, we need to grasp it, reorient it until the opening is facing down, and then turn it back upright and place it on the table.</p>
  
    <h2>Steps:</h2>
    <ol>
        <li><strong>Grasp the pink cup:</strong> The robot will move its arm towards the pink cup and grasp it from the side. After this step, the pink cup should be held in the robot's gripper with a horizontal orientation.
            <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name="pink cup", grasp_approach="from the side")</code></pre>
        </li>
        <li><strong>Reorient the gripper to pour out the contents:</strong> The robot will rotate its gripper to a vertical orientation. This will result in the pink cup being upside down, allowing its contents to fall out.
            <pre style="overflow-wrap: anywhere;"><code>robot_api.reorient(desired_gripper_orientation="vertical")</code></pre>
        </li>
        <li><strong>Reorient the gripper back to horizontal:</strong> The robot will rotate its gripper back to a horizontal orientation. This will bring the pink cup back to an upright orientation.
            <pre style="overflow-wrap: anywhere;"><code>robot_api.reorient(desired_gripper_orientation="horizontal")</code></pre>
        </li>
        <li><strong>Place the pink cup on the table:</strong> The robot will move its arm back to the table and place the pink cup back down. The pink cup should now be upright and empty on the table.
            <pre style="overflow-wrap: anywhere;"><code>robot_api.place_object(object_name="pink cup", location="here")</code></pre>
        </li>
    </ol>
  
    <p>This sequence of actions should successfully pour the contents of the pink cup and place it back on the table.</p>
  
  </div>
  </div>


<!-- Example 3 -->
<div class="example-slide">
  <div class="example-left">
    <figure>
      <img src="assets/gemini_input/pouring/3.png" alt="Example 3 Input Image">
      <figcaption>This is a picture of the scene. Please pour contents out of the pink cup and place it back upright on the table.</figcaption>
    </figure>
  </div>
  <div class="example-right">
    <p>Here are the steps to complete this task:</p>
    <ol>
        <li><strong>Grasp the pink cup from the side:</strong> The robot should grasp the cup from the side to get a firm grip for pouring.
            <ul>
                <li><strong>State change:</strong> The robot is now grasping the pink cup from the side, the cup is still upright.</li>
            </ul>
        </li>
        <li><strong>Lift the cup:</strong> Lift the cup to ensure it's clear of any obstacles.
            <ul>
                <li><strong>State change:</strong> The pink cup is now raised above the table and grasped by the robot.</li>
            </ul>
        </li>
        <li><strong>Reorient the gripper to vertical:</strong> This will tilt the cup to pour out the contents.
            <ul>
                <li><strong>State change:</strong> The pink cup is now tilted with its opening facing down, allowing the contents to fall out.</li>
            </ul>
        </li>
        <li><strong>Reorient the gripper to horizontal:</strong> This will bring the cup back to an upright position.
            <ul>
                <li><strong>State change:</strong> The pink cup is now upright again.</li>
            </ul>
        </li>
        <li><strong>Place the cup back on the table:</strong> Gently lower the cup onto the table.
            <ul>
                <li><strong>State change:</strong> The pink cup is now resting upright on the table.</li>
            </ul>
        </li>
    </ol>

    <h2>Python code:</h2>
    <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name="pink cup", grasp_approach="from the side")
robot_api.lift_object(object_name="pink cup") 
robot_api.reorient(desired_gripper_orientation="vertical")
robot_api.reorient(desired_gripper_orientation="horizontal")
robot_api.place_object(object_name="pink cup", location="here")</code></pre>  
  </div>
</div>
  
<!-- Example 4 -->
<div class="example-slide">
<div class="example-left">
  <img src="assets/gemini_input/pouring/4.png" alt="Example 4 Input Image">
  <figcaption>This is a picture of the scene. Please pour contents out of the pink cup and place it back upright on the table.</figcaption>
</div>
<div class="example-right">
  <h2>Plan:</h2>
  <ol>
      <li>Grasp the pink cup from the side.</li>
      <li>Lift the cup up.</li>
      <li>Tilt the cup over to pour out its contents.</li>
      <li>Tilt the cup back upright.</li>
      <li>Place the cup back on the table.</li>
  </ol>

  <h2>Python code:</h2>
  <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name='pink cup', grasp_approach='from the side') # Cup is grasped from the side, fingers oriented horizontally.
robot_api.lift_object(object_name='pink cup') # Cup is now held in the air.
robot_api.reorient(desired_gripper_orientation='vertical') # Cup is now tilted, contents poured out.
robot_api.reorient(desired_gripper_orientation='horizontal') # Cup is now upright again.
robot_api.place_object(object_name='pink cup', location='here') # Cup is placed back on the table.</code></pre>

  <h2>Reasoning for Grasping Approach:</h2>
  <ol>
      <li><strong>Pouring Clearance:</strong> Grasping from the side allows for a more natural and efficient pouring motion. When the gripper is oriented horizontally, rotating it to "vertical" naturally tips the cup forward, facilitating the pouring action.</li>
      <li><strong>Stability:</strong> Grasping from the side provides a more stable grip on the cup, especially when tilting it to pour out the contents. This reduces the risk of the cup slipping from the gripper's grasp.</li>
  </ol>
  <p>While a "top-down" grasp might seem intuitive for picking up a cup, it would require more complex manipulations to achieve the desired pouring angle, potentially increasing the risk of spilling or dropping the cup.</p>
</div>
</div>

<!-- Example 5 -->
<div class="example-slide">
<div class="example-left">
  <img src="assets/gemini_input/pouring/5.png" alt="Example 5 Input Image">
  <figcaption>This is a picture of the scene. Please pour contents out of the pink cup and place it back upright on the table.</figcaption>
</div>
<div class="example-right">
  <p>I see the pink cup and understand the task. Here are the steps to accomplish it:</p>
  <ol>
      <li><strong>Grasp cup:</strong> Grasp the pink cup from the side.
          <ul>
              <li>The cup will be in the robot's gripper, held horizontally.</li>
          </ul>
      </li>
      <li><strong>Lift and reorient cup:</strong> Lift the cup and reorient the gripper to vertical.
          <ul>
              <li>The cup will be held above the table, tilted so that the opening is facing down.</li>
          </ul>
      </li>
      <li><strong>Pour contents:</strong> Move the cup over the table and rotate the gripper to horizontal.
          <ul>
              <li>The contents of the cup will be poured onto the table, and the cup will be upside down in the robot's grip.</li>
          </ul>
      </li>
      <li><strong>Reorient cup upright:</strong> Rotate the gripper back to vertical.
          <ul>
              <li>The cup will be upright but still grasped.</li>
          </ul>
      </li>
      <li><strong>Place cup:</strong> Place the cup back on the table.
          <ul>
              <li>The cup will be back in its original location, upright and empty.</li>
          </ul>
      </li>
  </ol>
  <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name="pink cup", grasp_approach="from the side")
robot_api.lift_object(object_name="pink cup")
robot_api.reorient(desired_gripper_orientation="vertical")
robot_api.reorient(desired_gripper_orientation="horizontal")
robot_api.reorient(desired_gripper_orientation="vertical")
robot_api.place_object(object_name="pink cup", location="here")</code></pre>
</div>
</div>

<!-- Example 6 -->
<div class="example-slide">
<div class="example-left">
  <img src="assets/gemini_input/pouring/6.png" alt="Example 6 Input Image">
  <figcaption>This is a picture of the scene. Please pour contents out of the pink cup and place it back upright on the table.</figcaption>
</div>
<div class="example-right">
  <p>The robot should be able to pour the contents out of the pink cup. However, without knowing what the contents of the cup are, it is difficult to predict how they will behave when the cup is tilted. Assuming the contents are loose, like marbles or small toys, the robot should be able to pour them out.</p>

  <p>Here are the steps to complete the task:</p>
  <ol>
      <li><strong>Grasp cup:</strong> Grasp the pink cup from the side. The cup will be held horizontally in the robot's gripper.
          <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name='pink cup', grasp_approach='from the side')</code></pre>
      </li>
      <li><strong>Lift cup:</strong> Lift the cup slightly to avoid hitting the table. The cup is still being held horizontally in the robot's gripper.
          <pre style="overflow-wrap: anywhere;"><code>robot_api.lift_object(object_name='pink cup')</code></pre>
      </li>
      <li><strong>Tilt cup:</strong> Rotate the gripper to reorient to a vertical position. The cup will be tilted, with the opening facing downward and the contents spilling out onto the table.
          <pre style="overflow-wrap: anywhere;"><code>robot_api.reorient(desired_gripper_orientation='vertical')</code></pre>
      </li>
      <li><strong>Return to horizontal:</strong> Rotate the gripper back to a horizontal orientation. The cup will be upright but still held by the robot.
          <pre style="overflow-wrap: anywhere;"><code>robot_api.reorient(desired_gripper_orientation='horizontal')</code></pre>
      </li>
      <li><strong>Place cup:</strong> Place the pink cup back on the table. The cup is back in its original position, empty and upright.
          <pre style="overflow-wrap: anywhere;"><code>robot_api.place_object(object_name='pink cup', location='here')</code></pre>
      </li>
      <li><strong>Reset robot:</strong> Return the robot arm to its neutral position.
          <pre style="overflow-wrap: anywhere;"><code>robot_api.reset()</code></pre>
      </li>
  </ol>
</div>
</div>

<!-- Example 7 -->
<div class="example-slide">
<div class="example-left">
  <img src="assets/gemini_input/pouring/7.png" alt="Example 7 Input Image">
  <figcaption>This is a picture of the scene. Please pour contents out of the pink cup and place it back upright on the table.</figcaption>
</div>
<div class="example-right">
  <p>I can do that. I will need to grasp the cup, turn it upside down, and then place it back on the table. Here are the steps I will take:</p>

  <ol>
      <li><strong>Grasp the cup:</strong> I will grasp the pink cup from the side. 
          <ul>
              <li>The cup will be in the robot's gripper.</li>
          </ul>
      </li>
      <li><strong>Reorient the cup:</strong> I will reorient the gripper to be vertical. 
          <ul>
              <li>The cup will now be upside down with its contents having fallen out onto the table.</li>
          </ul>
      </li>
      <li><strong>Reorient the cup:</strong> I will reorient the gripper to be horizontal. 
          <ul>
              <li>The cup will now be right-side up.</li>
          </ul>
      </li>
      <li><strong>Place the cup:</strong> I will place the cup back on the table. 
          <ul>
              <li>The cup will be back on the table, upright and empty.</li>
          </ul>
      </li>
  </ol>

  <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name="pink cup", grasp_approach="from the side")
robot_api.reorient(desired_gripper_orientation="vertical")
robot_api.reorient(desired_gripper_orientation="horizontal")
robot_api.place_object(object_name="pink cup", location="here")</code></pre>
</div>
</div>

<!-- Example 8 -->
<div class="example-slide">
<div class="example-left">
  <img src="assets/gemini_input/pouring/8.png" alt="Example 8 Input Image">
  <figcaption>This is a picture of the scene. Please pour contents out of the pink cup and place it back upright on the table.</figcaption>
</div>
<div class="example-right">
  <p>Here are the steps to complete the task:</p>

    <ol>
        <li><strong>Grasp the pink cup from the side:</strong> The robot should approach the pink cup and grasp it from the side, so the cup is held horizontally.
            <ul>
                <li><strong>Expected state:</strong> The robot is now holding the pink cup horizontally with its contents still inside.</li>
            </ul>
        </li>
        <li><strong>Reorient the gripper to vertical:</strong> This will rotate the cup to pour out the contents onto the table.
            <ul>
                <li><strong>Expected state:</strong> The pink cup is now empty, and the contents are on the table. The robot is holding the cup upside down.</li>
            </ul>
        </li>
        <li><strong>Reorient the gripper to horizontal:</strong> This will rotate the cup back to a horizontal orientation.
            <ul>
                <li><strong>Expected state:</strong> The pink cup is now empty and held horizontally by the robot.</li>
            </ul>
        </li>
        <li><strong>Place the cup back on the table:</strong> The robot will place the empty cup back on the table.
            <ul>
                <li><strong>Expected state:</strong> The pink cup is now sitting upright and empty on the table.</li>
            </ul>
        </li>
    </ol>

    <p>Here is the python code to execute these steps:</p>
    <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name='pink cup', grasp_approach='from the side')
robot_api.reorient(desired_gripper_orientation='vertical')
robot_api.reorient(desired_gripper_orientation='horizontal')
robot_api.place_object(object_name='pink cup', location='here')</code></pre>
</div>
</div>

<!-- Example 9 -->
<div class="example-slide">
<div class="example-left">
  <img src="assets/gemini_input/pouring/9.png" alt="Example 9 Input Image">
  <figcaption>This is a picture of the scene. Please pour contents out of the pink cup and place it back upright on the table.</figcaption>
</div>
<div class="example-right">
  <p>Okay, here's how I'll approach this:</p>

  <ol>
      <li><strong>Grasp the cup:</strong> I'll grasp the pink cup from the side to have a secure grip for pouring.
          <ul>
              <li><strong>Expected state:</strong> The robot's gripper is securely grasping the pink cup from the side. The cup is lifted slightly off the table.</li>
          </ul>
      </li>
      <li><strong>Reorient the cup:</strong> I'll reorient my gripper to a vertical orientation to prepare for pouring.
          <ul>
              <li><strong>Expected state:</strong> The robot's gripper is now oriented vertically, holding the pink cup sideways above the table.</li>
          </ul>
      </li>
      <li><strong>Pour out the contents:</strong>  I'll maintain the grip and rotate the cup to pour out its contents onto the table.
          <ul>
              <li><strong>Expected state:</strong> The pink cup is now empty, with its contents poured out onto the table. The robot is still holding the cup sideways.</li>
          </ul>
      </li>
      <li><strong>Reorient the cup (again):</strong> I'll reorient my gripper back to a horizontal orientation.
          <ul>
              <li><strong>Expected state:</strong> The robot is now holding the empty pink cup upright.</li>
          </ul>
      </li>
      <li><strong>Place the cup:</strong> I'll carefully place the empty pink cup back on the table.
          <ul>
              <li><strong>Expected state:</strong> The empty pink cup is now resting upright on the table.</li>
          </ul>
      </li>
  </ol>

  <p>Here's the Python code using the provided API:</p>
  <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name="pink cup", grasp_approach="from the side")
robot_api.reorient(desired_gripper_orientation="vertical")
# Assuming there's no specific API call for pouring, 
# the following is a hypothetical way to achieve it:
robot_api.reorient(desired_gripper_orientation="horizontal") 
robot_api.reorient(desired_gripper_orientation="vertical")
robot_api.place_object(object_name="pink cup", location="here")</code></pre>
</div>
</div>

<!-- Example 10 -->
<div class="example-slide">
<div class="example-left">
  <img src="assets/gemini_input/pouring/10.png" alt="Example 10 Input Image">
  <figcaption>This is a picture of the scene. Please pour contents out of the pink cup and place it back upright on the table.</figcaption>
</div>
<div class="example-right">
  <p>Here are the steps to pour the contents out of the pink cup and place it back upright on the table:</p>

    <ol>
        <li><strong>Grasp the cup:</strong>  Grasp the pink cup from the side.
            <ul>
                <li><strong>Expected state:</strong> The robot is holding the pink cup upright in its gripper.</li>
            </ul>
        </li>
        <li><strong>Lift the cup:</strong> Lift the cup to a few inches above the table.
            <ul>
                <li><strong>Expected state:</strong> The robot is holding the pink cup in the air above its original position.</li>
            </ul>
        </li>
        <li><strong>Tilt the cup:</strong> Reorient the gripper to horizontal. This will tilt the cup so that the opening is facing downwards.
            <ul>
                <li><strong>Expected state:</strong> The pink cup is tilted upside down, with the contents pouring out onto the table. The robot is holding the cup in this orientation.</li>
            </ul>
        </li>
        <li><strong>Return the cup to an upright orientation:</strong> Reorient the gripper to vertical. The cup should now be upright again.
            <ul>
                <li><strong>Expected state:</strong> The pink cup is now empty and back in an upright orientation, held by the robot above the table.</li>
            </ul>
        </li>
        <li><strong>Lower the cup:</strong>  Lower the cup back to the table.
            <ul>
                <li><strong>Expected state:</strong> The empty pink cup is resting upright on the table.</li>
            </ul>
        </li>
        <li><strong>Release the cup:</strong> Release the grip on the cup.
            <ul>
                <li><strong>Expected state:</strong>  The empty pink cup remains on the table, and the robot's gripper is empty.</li>
            </ul>
        </li>
    </ol>

    <p>Here is the Python code using the provided API:</p>
    <pre style="overflow-wrap: anywhere;"><code>robot_api.grasp_object(object_name='pink cup', grasp_approach='from the side')
robot_api.lift_object(object_name='pink cup')
robot_api.reorient(desired_gripper_orientation='horizontal')
robot_api.reorient(desired_gripper_orientation='vertical')
robot_api.place_object(object_name='pink cup', location='here') 
robot_api.reset()</code></pre>
</div>
</div>

</div>

<!-- Right arrow to navigate through examples -->
<button class="carousel-button right" onclick="nextExample('exampleCarousel4')">&#10095;</button>
</div>

</section>

<script src="script.js"></script>

<section>
  <h2>Acknowledgments</h2>
  <p style="text-align: center; font-size: small;">
    This website was heavily inspired by <a href="https://brentyi.github.io/tilted/"> Brent Yi's</a>.
  </p>
</section>

</body>
</html>
